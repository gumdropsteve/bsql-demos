{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CsdVW7SU9Li"
   },
   "source": [
    "# Zillow Kaggle Competition on RAPIDS AI\n",
    "\n",
    "Initially based off eswar3's [Notebook](https://github.com/eswar3/Zillow-prediction-models/blob/master/Step%202a-Approach1.ipynb) for the Zillow Prize: Zillow’s Home Value Prediction (Zestimate) [Kaggle competition](https://www.kaggle.com/c/zillow-prize-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lpa1b4edIXuT"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKN5zuROroJD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "import cuml \n",
    "import numpy as np\n",
    "from blazingsql import BlazingContext\n",
    "bc = BlazingContext(pool=False)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import getcwd\n",
    "data_dir = f'{getcwd()}/data/zillow_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJeywzd2efw7"
   },
   "source": [
    "## Data\n",
    "\n",
    "`properties_2016`\n",
    "- aprox. 27,000,000 residential properties \n",
    "- 58 attributes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyblazing.apiv2.context.BlazingTable at 0x7f2dddc5b610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_types = ['int64', 'float64', 'float64','float64', 'float64', 'float64', 'float64', 'float64', \n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'str', 'float64', \n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "             'str', 'float64', 'str', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "             'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', 'float64', \n",
    "             'float64', 'str', 'float64', 'float64', 'float64', 'float64', 'float64', 'str', \n",
    "             'float64', 'float64']\n",
    "\n",
    "bc.create_table('prop2016', f'{data_dir}/properties_2016.csv', header=0, dtype=col_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_2016_v2`\n",
    "- 90,000 transaction records for closings in the year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyblazing.apiv2.context.BlazingTable at 0x7f2dddc51dd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_types = ['int', 'float', 'date']\n",
    "\n",
    "bc.create_table('train2016', f'{data_dir}/train_2016_v2.csv', \n",
    "                dtype=col_types, header=0, parse_dates=[\"transactiondate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Data \n",
    "\n",
    "In this approach the properties data and transaction data are merged together before adressing any missing values\n",
    "\n",
    "Merge datasets on `property_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_query = '''\n",
    "             SELECT \n",
    "                 train2016.logerror, train2016.transactiondate,\n",
    "                 prop2016.*\n",
    "             FROM \n",
    "                 prop2016\n",
    "             JOIN \n",
    "                 train2016\n",
    "                     ON (prop2016.parcelid = train2016.parcelid)\n",
    "                     '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGiscxESJDrl"
   },
   "source": [
    "So the data is easier to understand, let's reorder and rename some of the less straightforwardly named columns; for example, `yardbuildingsqft17` to `patio_sqft` and `structuretaxvaluedollarcnt` to `structure_tax`.\n",
    "\n",
    "Add `transaction_month` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>total_bath</th>\n",
       "      <th>full_bath</th>\n",
       "      <th>half_bath</th>\n",
       "      <th>...</th>\n",
       "      <th>regionidneighborhood</th>\n",
       "      <th>regionidzip</th>\n",
       "      <th>roomcnt</th>\n",
       "      <th>typeconstructiontypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>unitcnt</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90272</th>\n",
       "      <td>13836541</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>268160.0</td>\n",
       "      <td>97006.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90273</th>\n",
       "      <td>12951461</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>null</td>\n",
       "      <td>96524.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90274</th>\n",
       "      <td>12952367</td>\n",
       "      <td>-0.0576</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>null</td>\n",
       "      <td>96523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       parcelid  logerror  transaction_month transactiondate  yearbuilt  \\\n",
       "90272  13836541    0.0169                  2      2016-02-09     1950.0   \n",
       "90273  12951461    0.0962                  7      2016-07-20     1955.0   \n",
       "90274  12952367   -0.0576                  5      2016-05-12     1952.0   \n",
       "\n",
       "       assessmentyear  bedroomcnt  total_bath  full_bath half_bath  ...  \\\n",
       "90272          2015.0         2.0         2.0        2.0      null  ...   \n",
       "90273          2015.0         2.0         2.0        2.0      null  ...   \n",
       "90274          2015.0         4.0         2.0        2.0      null  ...   \n",
       "\n",
       "       regionidneighborhood  regionidzip roomcnt  typeconstructiontypeid  \\\n",
       "90272              268160.0      97006.0     6.0                    null   \n",
       "90273                  null      96524.0     0.0                    null   \n",
       "90274                  null      96523.0     0.0                    null   \n",
       "\n",
       "       architecturalstyletypeid unitcnt numberofstories fireplaceflag  \\\n",
       "90272                      null    null             1.0          None   \n",
       "90273                      null     1.0            null          None   \n",
       "90274                      null     1.0            null          None   \n",
       "\n",
       "      taxdelinquencyflag taxdelinquencyyear  \n",
       "90272               None               null  \n",
       "90273               None               null  \n",
       "90274               None               null  \n",
       "\n",
       "[3 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_cols = f'''\n",
    "               SELECT\n",
    "                   parcelid, logerror,\n",
    "                   MONTH(transactiondate) AS transaction_month, transactiondate,\n",
    "                   yearbuilt,\n",
    "                   assessmentyear,\n",
    "                   bedroomcnt,\n",
    "                   bathroomcnt AS total_bath, fullbathcnt AS full_bath, threequarterbathnbr AS half_bath,\n",
    "                   calculatedfinishedsquarefeet AS total_finished_living_area_sqft,\n",
    "                   lotsizesquarefeet AS lot_area_sqft,\n",
    "                   decktypeid AS deck_flag, yardbuildingsqft17 AS patio_sqft,\n",
    "                   pooltypeid7 AS pool_with_spa_tub_no, pooltypeid2 AS pool_with_spa_tub_yes,\n",
    "                   hashottuborspa AS has_hottub_or_spa, pooltypeid10 AS just_hottub_or_spa,\n",
    "                   finishedsquarefeet12 AS finished_living_area_sqft,\n",
    "                   finishedsquarefeet50 AS finished_living_area_entryfloor_sqft1,\n",
    "                   finishedfloor1squarefeet AS finished_living_area_entryfloor_sqft2,\n",
    "                   finishedsquarefeet6 AS base_unfinished_and_finished_area_sqft,\n",
    "                   finishedsquarefeet15 AS total_area_sqft,\n",
    "                   finishedsquarefeet13 AS preimeter_living_area_sqft,\n",
    "                   taxvaluedollarcnt AS total_parcel_tax,\n",
    "                   landtaxvaluedollarcnt AS land_tax, taxamount AS total_property_tax_2016, structuretaxvaluedollarcnt AS structure_tax,\n",
    "                   garagecarcnt, garagetotalsqft AS garage_sqft,\n",
    "                   yardbuildingsqft26 AS storage_sqft,\n",
    "                   fireplacecnt AS fireplace_count,\n",
    "                   buildingqualitytypeid  AS building_quality_id,\n",
    "                   heatingorsystemtypeid AS heating_system_id, airconditioningtypeid AS ac_id,\n",
    "                   storytypeid AS basement_flag, basementsqft AS basement_sqft,\n",
    "                   poolcnt AS pool_count, poolsizesum AS pool_sqft,\n",
    "                   buildingclasstypeid, buildingqualitytypeid,\n",
    "                   calculatedbathnbr,\n",
    "                   fips, latitude, longitude,\n",
    "                   propertycountylandusecode, propertylandusetypeid, propertyzoningdesc,\n",
    "                   rawcensustractandblock, censustractandblock,\n",
    "                   regionidcity, regionidcounty, regionidneighborhood, regionidzip,\n",
    "                   roomcnt,\n",
    "                   typeconstructiontypeid, architecturalstyletypeid,\n",
    "                   unitcnt,\n",
    "                   numberofstories,\n",
    "                   fireplaceflag,\n",
    "                   taxdelinquencyflag, taxdelinquencyyear\n",
    "               FROM (\n",
    "                   {join_query}\n",
    "                   )\n",
    "                   '''\n",
    "    \n",
    "df_train = bc.sql(rename_cols)\n",
    "\n",
    "df_train.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "\n",
    "# d = cudf.DataFrame()\n",
    "\n",
    "# d['column_names'] = df_train.columns\n",
    "# d['null_percent'] = [np.sum(df_train[col].isna()) / len(df_train[col]) for col in df_train.columns]\n",
    "\n",
    "# d.to_pandas().plot(kind='bar', x='column_names', y='null_percent', \n",
    "#                    figsize=(30, 10), fontsize=20, title='Null % by Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdtyBI2jFnJv"
   },
   "source": [
    "## Conforming Attribute Values\n",
    "### #0 boolean columns & null = 0s cases \n",
    "* `pool_count`, `pool_with_spa_tub_no` and `pool_with_spa_tub_yes` are all binary variables, replace all NULL values with zero\n",
    "*   `basement_flag` has values 7 & `Null` but is supposed to be bool, convert the `7`s to `1`s and the `Null`s to `0`s \n",
    "* patio and shed variables with null values are assumed to have none\n",
    "* deck_flag has only 2 values, `66` and `null`\n",
    "  - convert it into binary flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3bPdNONHTYI"
   },
   "outputs": [],
   "source": [
    "# replace missing pool count values so we booling\n",
    "the_bool_club = ['pool_count','pool_with_spa_tub_no','pool_with_spa_tub_yes',\n",
    "                 'basement_flag','patio_sqft','storage_sqft', 'deck_flag']\n",
    "\n",
    "for col in the_bool_club:\n",
    "  # convert null values to 0\n",
    "  df_train[col]=df_train[col].fillna(0)\n",
    "\n",
    "# convert 7s and 66s to 1s\n",
    "df_train['basement_flag'] = df_train['basement_flag'].replace(7, 1)\n",
    "df_train['deck_flag'] = df_train['deck_flag'].replace(66, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MbGy6r7JLLD"
   },
   "source": [
    "### #1 The pool\n",
    "*   When pool is present and if it has tub/spa then `just_hottub_or_spa` = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "B3-1V93smA9A",
    "outputId": "52e1a5d7-869a-443f-ac2d-40504992dc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.0    1161\n",
      "Name: just_hottub_or_spa, dtype: int32\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot broadcast <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dca6dd7af4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m conditions = ((df_train['pool_count'] == 1) \n\u001b[1;32m      5\u001b[0m               \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_hottub_or_spa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m               & (df_train['just_hottub_or_spa'].isna() == True))\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# then just_hottub_or_spa = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjust_hottub_or_spa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m_unordered_compare\u001b[0;34m(self, other, cmpops)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mlibcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvtx_range_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDF_UNORDERED_COMP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0mresult_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0moutcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmpops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m_normalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/column/string.py\u001b[0m in \u001b[0;36mnormalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot broadcast {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_na_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot broadcast <class 'int'>"
     ]
    }
   ],
   "source": [
    "print(f'before\\n{df_train.just_hottub_or_spa.value_counts()}\\n')\n",
    "\n",
    "# if poolcnt=1 and has_hottub_or_spa=1 and just_hottub_or_spa is null\n",
    "conditions = ((df_train['pool_count'] == 1) \n",
    "              & (df_train['has_hottub_or_spa'] == 1) \n",
    "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
    "# then just_hottub_or_spa = 0\n",
    "df_train.just_hottub_or_spa.loc[conditions] = 0\n",
    "\n",
    "print(f'after\\n{df_train.just_hottub_or_spa.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6E3-_XlSGBs"
   },
   "source": [
    "\n",
    "- when `has_hottub_or_spa` is null and `just_hottub_or_spa` is null\n",
    "  - both should be zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xa12WFccSGM6"
   },
   "outputs": [],
   "source": [
    "# if both has hottub and just hottub are null\n",
    "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
    "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
    "# just hottub or spa = 0 \n",
    "df_train.just_hottub_or_spa.loc[conditions] = 0\n",
    "\n",
    "# now, if has hottub is null and just hottub is 0 \n",
    "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
    "              & (df_train['just_hottub_or_spa'] == 0))\n",
    "# has hottub or spa = 0 \n",
    "df_train.has_hottub_or_spa.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5umCCWN73qxw"
   },
   "source": [
    "- when there is no pool\n",
    "  - if there is tub/spa \n",
    "    - then `just_hottub_or_spa`  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "FBgs7zJm3qk-",
    "outputId": "78c76ac5-2b7f-4f98-9615-8a335bc3214e"
   },
   "outputs": [],
   "source": [
    "# when poolcnt=0, has_hottub_or_spa=1\n",
    "conditions = ((df_train['pool_count'] == 0) \n",
    "              & (df_train['has_hottub_or_spa'] == 1))\n",
    "# just_hottub_or_spa=1\n",
    "df_train.just_hottub_or_spa.loc[conditions] = 1\n",
    "\n",
    "# let's check the values\n",
    "df_train.just_hottub_or_spa.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LsRr1aoSCVx"
   },
   "source": [
    "*   When there is no pool, set pool size to zero instead of na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtdyXCbx0TKx"
   },
   "outputs": [],
   "source": [
    "# where there is no pool\n",
    "conditions = df_train['pool_count']==0\n",
    "# square footage of non existant pool is 0 \n",
    "df_train.pool_sqft.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQFkXmAgQPY"
   },
   "source": [
    "#### #2 The basement\n",
    "\n",
    "Where `basement_flag` is zero, `basement_sqft` should also be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMuCOqAmLTmY"
   },
   "outputs": [],
   "source": [
    "# where there is no basement\n",
    "conditions = df_train['basement_flag'] == 0\n",
    "# fun fact: we just did this with the pool\n",
    "df_train.basement_sqft.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU6Uohb-PDYB"
   },
   "source": [
    "#### #3 The fireplace\n",
    "\n",
    "There seems to be inconsistency between the `fireplace_flag` and `fireplace_count`.\n",
    "- 90,053 flag values are null\n",
    "- 80,688 `fireplace_count` values are null\n",
    "    * 9,385 (-11.5%) difference, but a boatload either way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OZM6lXmmpj5k",
    "outputId": "ecf62d1d-b036-41ad-8052-a3090ae590ef"
   },
   "outputs": [],
   "source": [
    "print(f\"there are {df_train['fireplace_count'].isna().sum()} fireplace_count nulls\\nthere are {df_train['fireplaceflag'].isna().sum()} fireplaceflag nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9ZAzFoIpkSF"
   },
   "source": [
    "* context driven solutions\n",
    "  * where neither flag nor count exists, `fireplaceflag == False`\n",
    "  *   when `fireplace_count` is more than zero `fireplaceflag` should be `True`\n",
    "  * if `fireplaceflag == False`, the `fireplace_count` is logically `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "i3YRZgU_qZhA",
    "outputId": "e45a7a96-2e1d-47d2-a0bd-48ece42cbb6e"
   },
   "outputs": [],
   "source": [
    "# null flags with null counts are zero\n",
    "conditions = ((df_train['fireplace_count'].isna()==True) \n",
    "              & (df_train['fireplaceflag'].isna()==True))\n",
    "df_train.fireplaceflag.loc[conditions] = False\n",
    "\n",
    "# true flags for positive fireplace counts\n",
    "conditions = df_train['fireplace_count'] > 0\n",
    "df_train.fireplaceflag.loc[conditions] = True\n",
    "\n",
    "# set fireplace count nulls to 0 where false flags are\n",
    "conditions = ((df_train['fireplace_count'].isna()==True) \n",
    "              & (df_train['fireplaceflag']==False))\n",
    "df_train.fireplace_count.loc[conditions] = 0\n",
    "\n",
    "print(f\"there are {df_train['fireplace_count'].isna().sum()} fireplace_count \\\n",
    "nulls\\nthere are {df_train['fireplaceflag'].isna().sum()} fireplaceflag nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYntUejosOn3"
   },
   "source": [
    "### #4 The garage\n",
    "*   Properties with no garages would have NA values for both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9mGs-mK9E0Q"
   },
   "outputs": [],
   "source": [
    "garage = ['garagecarcnt', 'garage_sqft']\n",
    "# where garage car count and garage square feet are null\n",
    "conditions = ((df_train['garagecarcnt'].isna()==True) \n",
    "              & (df_train['garage_sqft'].isna()==True))\n",
    "# set both to 0\n",
    "df_train[garage].loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uV115W6-ohW"
   },
   "source": [
    "Exploring the data farther, we see\n",
    "- `garage_sqft` holds over 8,900 measurements of 0 despite the garage's car count being 1 or more  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "gbbUIbwJ-ouS",
    "outputId": "310a4cdf-01a0-4fc3-ed1b-0e2f5e668518"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>garage_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    garagecarcnt  garage_sqft\n",
       "24           1.0          0.0\n",
       "34           1.0          0.0\n",
       "57           2.0          0.0\n",
       "60           1.0          0.0\n",
       "89           1.0          0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show rows where garage count and square feet don't add up\n",
    "conditions = (df_train.garagecarcnt > 0) & (df_train.garage_sqft == 0)\n",
    "\n",
    "# give a display\n",
    "df_train.loc[conditions][garage].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I1O76QKA8Cb"
   },
   "source": [
    "- these 0 values need to be null\n",
    " - because no garage holding 1 or more cars in 2016 measured 0sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWVtoty0A9Jt"
   },
   "outputs": [],
   "source": [
    "# where garage count and square feet don't add up\n",
    "conditions = (df_train.garagecarcnt>0) & (df_train.garage_sqft==0)\n",
    "# insert a NaN value\n",
    "df_train.garage_sqft.loc[conditions] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seb6r5wx5Bbz"
   },
   "source": [
    "### #5 The bath\n",
    "*   `total_bath` & `calculatedbathnbr` are near-duplicates w/ `calculated` having more nulls\n",
    "  - let's drop it\n",
    "*   if `full_bath` is null and `half_bath` is also null\n",
    "  - let's make `total_bath` = 0 \n",
    "      - because we can't truthfully assume it's any more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgMNToed5BMu"
   },
   "outputs": [],
   "source": [
    "# drop calculated bath column\n",
    "df_train = df_train.drop('calculatedbathnbr', axis=1)\n",
    "\n",
    "# if full_bath is null & half_bath is null\n",
    "conditions = ((df_train['full_bath'].isnull()==True) \n",
    "              & (df_train['half_bath'].isnull()==True) \n",
    "              & (df_train['total_bath']==0))\n",
    "# total_bath=0\n",
    "df_train.total_bath.loc[conditions] = np.nan\n",
    "\n",
    "# when full_bath==total_bath, half_bath=0 \n",
    "df_train.half_bath.loc[df_train.full_bath == df_train.total_bath] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code fips code with respective county names\n",
    "-  6037- LA\n",
    "-  6059- Orange_County\n",
    "-  6111- Ventura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "0\n",
      "6037.0    58574\n",
      "6059.0    24505\n",
      "6111.0     7196\n",
      "Name: fips, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(df_train.fips.dtype)\n",
    "print(df_train.fips.isnull().sum())\n",
    "print(df_train.fips.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0\n",
      "LA               58574\n",
      "Orange_County    24505\n",
      "Ventura           7196\n",
      "Name: fips, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.to_pandas()\n",
    "\n",
    "df_train.loc[df_train.fips==6037, 'fips'] = 'LA'\n",
    "df_train.loc[df_train.fips==6059, 'fips'] = 'Orange_County'\n",
    "df_train.loc[df_train.fips==6111, 'fips'] = 'Ventura'\n",
    "\n",
    "bc.create_table('df_train', df_train)\n",
    "df_train = bc.sql('select * from df_train')\n",
    "\n",
    "print(df_train.fips.dtype)\n",
    "print(df_train.fips.isnull().sum())\n",
    "print(df_train.fips.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sh8cG0pr4_hl"
   },
   "source": [
    "### #6 Mode Imputation \n",
    "* scaling down the latitude and longitide\n",
    "  - knn imput takes more time due to the larger numbers\n",
    "  - standardizing gives better results on most algorithms\n",
    "    - this is a competition, we came to win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kitrNxKgLWUd"
   },
   "outputs": [],
   "source": [
    "df_train['latitude'] = df_train.latitude / 100000\n",
    "df_train['longitude'] = df_train.longitude / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6bhRhu5YZ1d"
   },
   "source": [
    "### #7 numberofstories & unitcnt & roomcnt\n",
    "* we can devise unit count based on property land type\n",
    "  - so we can now go ahead and correct the unit counts for each given property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where room count is 0, go ahead and NaN it\n",
    "df_train.roomcnt.loc[df_train['roomcnt'] == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0      54503\n",
       "2.0       2354\n",
       "4.0        871\n",
       "3.0        619\n",
       "5.0          1\n",
       "6.0          1\n",
       "9.0          1\n",
       "11.0         1\n",
       "70.0         1\n",
       "143.0        1\n",
       "Name: unitcnt, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.unitcnt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "propertylandusetypeid & unitcnt are related \n",
    "  these are the propertylandusetypeid codes & their definitions\n",
    "  \n",
    "#246 -Duplex (2 Units, Any Combination)\n",
    "#247 -Triplex (3 Units, Any Combination)\n",
    "#248 -Quadruplex (4 Units, Any Combination)\n",
    "#260 -Residential General\n",
    "#261 -Single Family Residential\n",
    "#263 -Mobile Home\n",
    "#264 -Townhouse\n",
    "#266 -Condominium\n",
    "#267 -Cooperative\n",
    "#269 -Planned Unit Development\n",
    "#275 -Residential Common Area \n",
    "#31 - Commercial/Office/Residential Mixed Used\n",
    "#47 -Store/Office (Mixed Use)\n",
    "#265 -Cluster Home\n",
    "\"\"\"\n",
    "\n",
    "# adjust conditions to one unit indicator\n",
    "ones = [260, 261, 263, 264, 266, 267, 269, 275]\n",
    "for one in ones:\n",
    "    conditions = ((df_train['propertylandusetypeid']==one) & (df_train['unitcnt'].isna()))\n",
    "    df_train.unitcnt.loc[conditions] = 1\n",
    "\n",
    "# two units \n",
    "twos = [31, 47, 246]\n",
    "for two in twos:\n",
    "    conditions = ((df_train['propertylandusetypeid']==two) & (df_train['unitcnt'].isna()))\n",
    "    df_train.unitcnt.loc[conditions] = 2\n",
    "\n",
    "# three units\n",
    "conditions = ((df_train['propertylandusetypeid']==247) & (df_train['unitcnt'].isna()))\n",
    "df_train.unitcnt.loc[conditions] = 3\n",
    "\n",
    "# four units\n",
    "conditions = ((df_train['propertylandusetypeid']==248) & (df_train['unitcnt'].isna()))\n",
    "df_train.unitcnt.loc[conditions] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "yHZH4rMNLfBA",
    "outputId": "97106bb4-10f2-49a9-f821-03a3972db136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0      86035\n",
       "2.0       2372\n",
       "4.0        884\n",
       "3.0        622\n",
       "5.0          1\n",
       "6.0          1\n",
       "9.0          1\n",
       "11.0         1\n",
       "70.0         1\n",
       "143.0        1\n",
       "Name: unitcnt, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how out unit counts look\n",
    "df_train.unitcnt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02yLicmxLs3C"
   },
   "source": [
    "### #8 Time to Cut\n",
    "**Because of the adjustments made so far a number of columns are no longer needed**\n",
    "*  transaction date column is no longer of use\n",
    "  - and can be dropped \n",
    "* `preimeter_living_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that `preimeter_living_area_sqft` has more duplicates\n",
    "* `total_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that \"total_area_sqft\" has more duplicates\n",
    "* `total_finished_living_area_sqft` and `finished_living_area_sqft` have the same values \n",
    "  - except that `finished_living_area_sqft` has more duplicates\n",
    "* `base_unfinished_and_finished_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that `base_unfinished_and_finished_area_sqft` has more duplicates\n",
    "* different counties follow different land use code\n",
    "  - to compare different counties, zillow has created it's own `propertylandusetypeid`\n",
    "    - hence we can drop `propertycountylandusecode`\n",
    "    - the same applies to `propertyzoningdesc`\n",
    "* Most zip id's either invalid or out of city\n",
    "  - since enough information about location is given in latitude and longitude \n",
    "    - let's drop other location related fields\n",
    "      - `regionidcity`\n",
    "      - `regionidzip`\n",
    "      - `regionidneighborhood`\n",
    "* `assessmentyear` has a constant value for all rows\n",
    "  - let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtOgzOqHLyid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: (90275, 61)\n",
      "AFTER:  (90275, 49)\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEFORE: {df_train.shape}\")\n",
    "\n",
    "# collect columns to drop\n",
    "cut = ['propertyzoningdesc','propertycountylandusecode',\n",
    "       'base_unfinished_and_finished_area_sqft','finished_living_area_sqft',\n",
    "       'total_area_sqft','preimeter_living_area_sqft','regionidzip',\n",
    "       'regionidcity','regionidneighborhood','assessmentyear','transactiondate',\n",
    "       'censustractandblock']\n",
    "# cut columns form dataframe\n",
    "df_train = df_train.drop(cut, axis=1)\n",
    "\n",
    "print(f\"AFTER:  {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icDvpvSD6BSb"
   },
   "source": [
    "### #9 Tax, Year, & Census\n",
    "-  if tax deliquency flag is null, assume there is no unpaid tax on the property\n",
    "  - an issue arrises here because `taxdelinquencyflag` is a StringColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['taxdelinquencyflag'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    88492\n",
       "1     1783\n",
       "Name: tdf, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.create_table('df_train', df_train)\n",
    "\n",
    "query = '''\n",
    "        SELECT \n",
    "            CASE WHEN taxdelinquencyflag = 'Y' THEN 1 ELSE 0 END as tdf\n",
    "        FROM\n",
    "            df_train\n",
    "            '''\n",
    "\n",
    "df_train['tdf'] = bc.sql(query)['tdf']\n",
    "\n",
    "df_train.tdf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5EAdWXaCTRU"
   },
   "source": [
    "- Convert years\n",
    "  - from yy\n",
    "    - to 2016 - yyyy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    628\n",
       "15.0    518\n",
       "13.0    210\n",
       "12.0    154\n",
       "10.0     89\n",
       "11.0     85\n",
       "9.0      63\n",
       "8.0      24\n",
       "7.0       8\n",
       "6.0       3\n",
       "99.0      1\n",
       "Name: taxdelinquencyyear, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.taxdelinquencyyear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.taxdelinquencyyear==99, 'taxdelinquencyyear'] = 1999\n",
    "df_train.loc[df_train.taxdelinquencyyear==6, 'taxdelinquencyyear'] = 2006\n",
    "df_train.loc[df_train.taxdelinquencyyear==7, 'taxdelinquencyyear'] = 2007\n",
    "df_train.loc[df_train.taxdelinquencyyear==8, 'taxdelinquencyyear'] = 2008\n",
    "df_train.loc[df_train.taxdelinquencyyear==9, 'taxdelinquencyyear'] = 2009\n",
    "df_train.loc[df_train.taxdelinquencyyear==10, 'taxdelinquencyyear'] = 2010\n",
    "df_train.loc[df_train.taxdelinquencyyear==11, 'taxdelinquencyyear'] = 2011\n",
    "df_train.loc[df_train.taxdelinquencyyear==12, 'taxdelinquencyyear'] = 2012\n",
    "df_train.loc[df_train.taxdelinquencyyear==13, 'taxdelinquencyyear'] = 2013\n",
    "df_train.loc[df_train.taxdelinquencyyear==14, 'taxdelinquencyyear'] = 2014\n",
    "df_train.loc[df_train.taxdelinquencyyear==15, 'taxdelinquencyyear'] = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014.0    628\n",
       "2015.0    518\n",
       "2013.0    210\n",
       "2012.0    154\n",
       "2010.0     89\n",
       "2011.0     85\n",
       "2009.0     63\n",
       "2008.0     24\n",
       "2007.0      8\n",
       "2006.0      3\n",
       "1999.0      1\n",
       "Name: taxdelinquencyyear, dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.taxdelinquencyyear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014.0    628\n",
       "2015.0    518\n",
       "2013.0    210\n",
       "2012.0    154\n",
       "2010.0     89\n",
       "2011.0     85\n",
       "2009.0     63\n",
       "2008.0     24\n",
       "2007.0      8\n",
       "2006.0      3\n",
       "1999.0      1\n",
       "Name: taxdelinquencyyear, dtype: int32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.to_pandas().loc[d.to_pandas().taxdelinquencyyear > 0, 'taxdelinquencyyear'] = 2016 - d.to_pandas()['taxdelinquencyyear']\n",
    "\n",
    "d.taxdelinquencyyear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "6Bic66I9LfGC",
    "outputId": "baaa5387-bbd7-4242-a336-0b6b90606935"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot broadcast <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b1eaf81a322f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# no delinquency? set year to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxdelinquencyyear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxdelinquencyflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# collect x and xx formatted delinquency years w/ matching xxxx year format pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m year_pairs = [(99,1999), (6,2006), (7,2007), (8,2008), (9,2009), (10,2010),\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m_unordered_compare\u001b[0;34m(self, other, cmpops)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mlibcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvtx_range_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDF_UNORDERED_COMP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0mresult_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0moutcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmpops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36m_normalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-stable/lib/python3.7/site-packages/cudf/core/column/string.py\u001b[0m in \u001b[0;36mnormalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot broadcast {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_na_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot broadcast <class 'int'>"
     ]
    }
   ],
   "source": [
    "# no delinquency? set year to 0\n",
    "df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyflag == 0] = 0\n",
    "\n",
    "# collect x and xx formatted delinquency years w/ matching xxxx year format pair\n",
    "year_pairs = [(99,1999), (6,2006), (7,2007), (8,2008), (9,2009), (10,2010),\n",
    "             (11,2011), (12,2012), (13,2013), (14,2014), (15,2015)]\n",
    "# go through the pairs individually \n",
    "for year in year_pairs:\n",
    "  # split the pair in question \n",
    "  old, new = year\n",
    "  # replace old year (e.g. 99) with new year (e.g. 1999)\n",
    "  df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear == old] = new\n",
    "\n",
    "# adjust delinquency year relative to training year (2016) \n",
    "df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear>0] = 2016 - df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear>0]\n",
    "\n",
    "# what've we got? \n",
    "df_train.taxdelinquencyyear.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya7xLHzdGVcs"
   },
   "source": [
    "- values in `rawcensustractandblock` represent multiple fields concatened together as float values\n",
    "  - by converting those values to string we can split each and build new columns:\n",
    "    - `census_tractnumber`\n",
    "    - `block_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttt=df_train.copy()\n",
    "df_train=ttt.copy()\n",
    "\n",
    "# origional column\n",
    "\"\"\"\n",
    "\n",
    "# both are float columns now\n",
    "#rawcensustractandblock\n",
    "s_rawcensustractandblock=df_train.rawcensustractandblock.apply(lambda x: str(x))\n",
    "\n",
    "df_train['census_tractnumber']=s_rawcensustractandblock.str.slice(4,11)\n",
    "df_train['block_number']=s_rawcensustractandblock.str.slice(start=11)\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: x[:4]+'.'+x[4:]+'0' )\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: int(round(float(x),0)) )\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: str(x).ljust(4,'0') )\n",
    "\n",
    "#droping censustractandblock since this is just a duplicate of rawcensustractandblock\n",
    "df_train=df_train.drop('censustractandblock', axis=1)\n",
    "\n",
    "# drooping rawcensustractandblock, since it's already stored as substrings in different column names\n",
    "df_train=df_train.drop('rawcensustractandblock', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "Sg0eN-K1QdZy",
    "outputId": "a90de47f-5c88-4834-df44-75a9dedcd07c"
   },
   "outputs": [],
   "source": [
    "# copy rawcensustractandblock with values as string instead of float\n",
    "string_data = cudf.Series(df_train['rawcensustractandblock'].values_to_string())\n",
    "\n",
    "# print(type(string_data))\n",
    "# print(len(string_data))\n",
    "# print(string_data)\n",
    "\n",
    "# \"\"\"\n",
    "# CURRENT ERROR IN CONVERSION OF VALUES\n",
    "# \"\"\"\n",
    "# print(f\"\\nNOTE: THERE APPEARS TO BE AN ERROR WHEN CONVERTING TO STRING\\n\"\n",
    "#       f\"  > somewhat random numbers added to end of some values\\n    >> e.g. 004, 006\"\n",
    "#       f\"\\n\\n\\ndf_train['rawcensustractandblock'].head(10).values\\n\"\n",
    "#       f\"{df_train['rawcensustractandblock'].head(10).values}\\n\\n\"\n",
    "#       f\"data.head(10).values\\n{string_data.head(10).values}\\n\\n\\n\"\n",
    "#       f\"THE SAME NUMBERS OCCOUR IN THE FIRST WHEN PUT INTO A LIST\\n\"\n",
    "#       f\"  > not sure how to deal with this now\\n\"\n",
    "#       f\"    >> difficult to reproduce without data\\n\\n\")\n",
    "# \"\"\"\n",
    "# CURRENT ERROR IN CONVERSION OF VALUES\n",
    "# \"\"\"\n",
    "\n",
    "# set new tract number \n",
    "df_train['census_tractnumber'] = string_data.str.slice(4, 11)\n",
    "\n",
    "# set/adjust block number\n",
    "df_train['block_number'] = string_data.str.slice(11)\n",
    "df_train['block_number'] = df_train.block_number.str.slice(0,4).str.cat(df_train.block_number.str.slice(4), '.')\n",
    "df_train['block_number'] = df_train.block_number.astype('float').round(0).astype('int')\n",
    "df_train['block_number'] = df_train.block_number.astype('str').str.ljust(4, '0')\n",
    "\n",
    "# drop raw census tract and block column, no longer needed\n",
    "df_train = df_train.drop('rawcensustractandblock', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "CORRECT NUMBERS THAT SHOULD BE DISPLAYED BY BELOW PRINT STATEMENT\n",
    "  > currently not being seen due to prior mentioned error\n",
    "\n",
    "tractnumber\n",
    "0    1066.46\n",
    "1    0524.22\n",
    "2    4638.00\n",
    "3    2963.00\n",
    "4    0423.38\n",
    "dtype: object\n",
    "\n",
    "blocknumber\n",
    "0    1001\n",
    "1    2024\n",
    "2    3004\n",
    "3    2002\n",
    "4    1006\n",
    "dtype: object\n",
    "\"\"\"\n",
    "df_train[['census_tractnumber', 'block_number']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T71orw51lpTN"
   },
   "source": [
    "## Dealing with Missing Values\n",
    "### #1 Setting standards\n",
    "- Despite corecting and adjusting the data to this point, there are still some columns holding a large majority of null values\n",
    "- For some columns, this majority represents over 95% of values\n",
    "  - Let's identify those columns\n",
    "    - And drop columns with more than 95% null values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "xhCosNpXvTVU",
    "outputId": "2d969756-decb-4912-94f6-19836eb0323a"
   },
   "outputs": [],
   "source": [
    "# calculate null value % for each column & frame it\n",
    "missingvalues_prop = (df_train.isnull().sum()/len(df_train)).reset_index()\n",
    "missingvalues_prop.columns = ['field','percentage']\n",
    "\n",
    "# sort by null values percentage, from highest % to lowest\n",
    "missingvalues_prop = missingvalues_prop.sort_values(by='percentage', \n",
    "                                                    ascending=False)\n",
    "# identify columns with > 95% of values null\n",
    "missingvaluescols = missingvalues_prop.loc[missingvalues_prop['percentage'] > 0.95]\n",
    "\n",
    "# display columns with highest % null values\n",
    "print(missingvaluescols)\n",
    "\n",
    "# drop columns with more than 95% null values\n",
    "df_train = df_train.drop(missingvaluescols['field'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "az6t2ntBCMRe"
   },
   "source": [
    "### #2 Working with Remaining Values\n",
    "- the majority of values still missing in unitcnt are rows were `propertylandusetypeid` = 265, \n",
    "  - which is Cluster Home (i.e. group of houses with shared walls)\n",
    "    - each cluster is anywhere between 5 to 25 units\n",
    "      - here we will asssume 10 units as reassonable count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "yB2lzAyopS_S",
    "outputId": "db6c7add-5452-4535-8948-a426654851b7"
   },
   "outputs": [],
   "source": [
    "# highly related propertylandusetypeid\n",
    "df_train['unitcnt'].loc[df_train['propertylandusetypeid'] == 265] = 10\n",
    "\n",
    "# let's see what we've got\n",
    "df_train['unitcnt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iR1rBlz-dOdH"
   },
   "source": [
    "- a number of pool sizes are null despite there being a pool\n",
    "  - let's calculate the average pool size\n",
    "    - and assume those null values are pools of average size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-icFDeLSoJwl",
    "outputId": "b1ed39c3-3a14-4dc1-eb48-b3429da5cffe"
   },
   "outputs": [],
   "source": [
    "# how's it look before?\n",
    "print(df_train.pool_sqft.isna().sum())\n",
    "\n",
    "# calculate the average pool square footage for properties with a pool(s)\n",
    "poolsizesum_mean = df_train.pool_sqft.loc[df_train['pool_count'] > 0].mean()\n",
    "\n",
    "# where the property has a pool(s) but pool square feet is 0\n",
    "conditions = ((df_train['pool_count'] > 0) \n",
    "              & (df_train['pool_sqft'].isna()==True))\n",
    "\n",
    "# set pool square feet to the average pool square footage of pool properties\n",
    "df_train['pool_sqft'].loc[conditions] = poolsizesum_mean\n",
    "\n",
    "# display new null count\n",
    "df_train.pool_sqft.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyGeXJfEmJBU"
   },
   "source": [
    "- total parcel tax\n",
    "- structure tax\n",
    "- land tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows have values in total parcel tax that do not add up given land tax and structure tax\n",
    "len(df_train.loc[df_train['total_parcel_tax'] != df_train['land_tax'] + df_train['structure_tax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.total_parcel_tax.isnull().sum())\n",
    "print(df_train.land_tax.isnull().sum())\n",
    "print()\n",
    "\n",
    "# where land tax is not a null value\n",
    "condition_1 = df_train.land_tax.isnull() == False\n",
    "# where total parceltax is not a null value\n",
    "condition_2 = df_train.total_parcel_tax.isnull()==False\n",
    "\n",
    "# pull the total parcel tax column\n",
    "total_parcel_tax_not_null = df_train.loc[condition_1 & condition_2, 'total_parcel_tax']\n",
    "# pull the land tax column\n",
    "land_tax_not_null = df_train.loc[condition_1 & condition_2, 'land_tax']\n",
    "\n",
    "# total_parcel_tax = structure_tax + land_tax\n",
    "# -> structure_tax = total_parcel_tax - land_tax\n",
    "correct_structure_tax = total_parcel_tax_not_null - land_tax_not_null\n",
    "\n",
    "# set the structure_tax values in rows where total and land taxes are not null to these correct values \n",
    "df_train['structure_tax'].loc[condition_1 & condition_2] = correct_structure_tax\n",
    "\n",
    "# where structure tax is still 0, there isn't structure tax\n",
    "df_train['structure_tax'].loc[df_train['structure_tax'] == 0] = np.nan\n",
    "\n",
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.total_parcel_tax.isnull().sum())\n",
    "print(df_train.land_tax.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows have values in total parcel tax that do not add up given land tax and structure tax\n",
    "len(df_train.loc[df_train['total_parcel_tax'] != df_train['land_tax'] + df_train['structure_tax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8SID48LOpYvu",
    "outputId": "6d20a3ba-4360-4554-908d-f6d673aece12"
   },
   "outputs": [],
   "source": [
    "# regionidcounty is exact copy of fips code, dropping the dulicate column\n",
    "df_train = df_train.drop(['regionidcounty'], axis=1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tWmM2J8_pkg1",
    "outputId": "6362e07f-e363-4884-b0c5-9380b5fee956"
   },
   "outputs": [],
   "source": [
    "#*******************************\n",
    "#bedroomcnt #1421 zero bed room houses ??, observed it's missing all other room count also missing\n",
    "# where there is no bedroom, null is a better representation \n",
    "\n",
    "# before\n",
    "print(len(df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0]))\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "\n",
    "df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0] = np.nan\n",
    "\n",
    "# after\n",
    "print(len(df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0]))\n",
    "print(df_train.bedroomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Room Count\n",
    "caluculate full bath and half bath again from total bath as it has few extra columns (fixes 500 missing values in roomcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "3qnP2L9LpmeJ",
    "outputId": "c0eabce4-3232-4435-8733-779526f18c57"
   },
   "outputs": [],
   "source": [
    "# propertylandusetypeid & total living area\n",
    "#                              total_bath           1165\n",
    "#                              full_bath           1182\n",
    "#                              half_bath           1182\n",
    "#                                bedroomcnt      1421\n",
    "#                              roomcnt           1416\n",
    "\n",
    "print(df_train.total_bath.isna().sum())\n",
    "print(df_train.full_bath.isnull().sum())\n",
    "print(df_train.half_bath.isnull().sum())\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.roomcnt.isnull().sum())\n",
    "print()\n",
    "\n",
    "# roomcnt = (full_bath + half_bath) + bedroomcnt\n",
    "# total_bath = fullbath+ 0.5(half_bath)\n",
    "\n",
    "# where full & half bath and bedroom count are not null, but room count is null\n",
    "conditions = ((df_train['full_bath'].isna() == False) \n",
    "              & (df_train['half_bath'].isna() == False) \n",
    "              & (df_train['bedroomcnt'].isna() == False) \n",
    "              & (df_train['roomcnt'].isna() == True))\n",
    "\n",
    "# calculate room count including all full & half baths along with bedroom count\n",
    "new_values = df_train.full_bath.loc[conditions] + df_train.half_bath.loc[conditions] + df_train.bedroomcnt.loc[conditions]\n",
    "\n",
    "# df_train['roomcnt'] = df_train['roomcnt'].masked_assign(new_values, conditions)\n",
    "df_train.roomcnt.loc[conditions] = new_values\n",
    "\n",
    "\n",
    "# most bedroom count and roomcount null are in same place\n",
    "# all column null count 1133 all columns are null\n",
    "\n",
    "print(df_train.total_bath.isna().sum())\n",
    "print(df_train.full_bath.isnull().sum())\n",
    "print(df_train.half_bath.isnull().sum())\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.roomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mvy51Ckev9CX"
   },
   "source": [
    "- correct number of stories by Zillow's `propertylandusetypeid` indicator\n",
    "  - where null values are not\n",
    "    - number of stories can be set to mode\n",
    "  - where there are null values\n",
    "    - number of stories can be set to the generally accepted number of stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IW4CG2InpolD",
    "outputId": "02375307-54e2-432b-8b87-1397c73d56b2"
   },
   "outputs": [],
   "source": [
    "# before (what's it look like?)\n",
    "print(f'BEFORE\\n{df_train.numberofstories.value_counts()}\\n'\n",
    "      f'{df_train.numberofstories.isnull().sum()} remaining null values\\n')\n",
    "\n",
    "#numberofstories\t69705\n",
    "\n",
    "# store ids and general number of stories \n",
    "zillow_type_ids = [(31,2), (246,2), (247,2), (248,2), (260,2), (261,1), \n",
    "                   (263,1), (266,1), (267,1), (269, 2), (275,1)]\n",
    "\n",
    "# go through each id pair \n",
    "for type_id in zillow_type_ids:\n",
    "    # split the pair into type id and number of stories\n",
    "    t_id, n_stories = type_id\n",
    "\n",
    "    # when type id matches and story count is not null\n",
    "    conditions = ((df_train['propertylandusetypeid'] == t_id) \n",
    "                  & (df_train['numberofstories'].isna() == False))\n",
    "\n",
    "    # calculate the mode story count for matching id properties\n",
    "    mode_stories = df_train.numberofstories.loc[conditions].value_counts()\n",
    "    \n",
    "    # when there is at least one value in the value_counts of this property type\n",
    "    if len(mode_stories) > 0:\n",
    "        # set mode stories to the most popular value\n",
    "        mode_stories = mode_stories[0]\n",
    "    # otherwise\n",
    "    else:\n",
    "        # set mode stories to the general average for this property type\n",
    "        mode_stories = n_stories\n",
    "\n",
    "    # and set those non null values to the most common value seen\n",
    "    df_train['numberofstories'].loc[conditions] = mode_stories\n",
    "\n",
    "    # when type id matches and story count is null\n",
    "    conditions = ((df_train['propertylandusetypeid'] == t_id) \n",
    "                  & (df_train['numberofstories'].isna() == False))\n",
    "    # set null values to the common number of stories seen in that type id\n",
    "    df_train['numberofstories'].loc[conditions] = n_stories\n",
    "\n",
    "# edge cases\n",
    "conditions = ((df_train.propertylandusetypeid==264) \n",
    "              & (df_train.numberofstories.isnull()))\n",
    "df_train.numberofstories.loc[conditions] = 2\n",
    "\n",
    "# what's it looking like? \n",
    "print(f'AFTER\\n{df_train.numberofstories.value_counts()}\\n'\n",
    "      f'{df_train.numberofstories.isnull().sum()} remaining null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "AHcMsDCxprd4",
    "outputId": "30481b2c-e035-4478-d62f-63e10a09c17e"
   },
   "outputs": [],
   "source": [
    "# before (what's it looking like?) \n",
    "print(f'BEFORE\\n{df_train.fireplace_count.value_counts()}\\n'\n",
    "      f'{df_train.fireplace_count.isnull().sum()} remaining null values\\n')\n",
    "\n",
    "# where there is a fire place, and count is not null\n",
    "conditions = ((df_train.fireplaceflag==1) \n",
    "              & (df_train.fireplace_count.isna() == False))\n",
    "# calculate the mode fireplace count \n",
    "mode_fire_count = df_train.loc[conditions, 'fireplace_count'].value_counts()[0]\n",
    "# and set those non null values to the most common fireplace count\n",
    "df_train['fireplace_count'].loc[conditions] = mode_fire_count\n",
    "\n",
    "# where there is a fire place, and count is null\n",
    "conditions = ((df_train.fireplaceflag==1) \n",
    "              & (df_train.fireplace_count.isna() == True))\n",
    "# set null values to the most common fireplace count\n",
    "df_train.fireplace_count.loc[conditions] = 1\n",
    "\n",
    "# after\n",
    "print(f'AFTER\\n{df_train.fireplace_count.value_counts()}\\n'\n",
    "      f'{df_train.fireplace_count.isnull().sum()} remaining null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "FIuSWoJspt3H",
    "outputId": "cb11c3a1-1658-4bce-cbde-a1a47ccdc0a8"
   },
   "outputs": [],
   "source": [
    "# set basic sns \n",
    "color = sns.color_palette()\n",
    "sns.set(style=\"darkgrid\")\n",
    "# convert dataframe to pandas for ease of use with sns\n",
    "pd_train = df_train.to_pandas()\n",
    "# set ax plot\n",
    "ax = sns.countplot(x=\"buildingqualitytypeid\", data=pd_train)\n",
    "# adjust fringe aesthetics\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Frequency of Bathroom count\", fontsize=15)\n",
    "# display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "KOHPCFRSp5y9",
    "outputId": "e0f3fe2e-a82a-49e8-a798-a3f79a30bcee"
   },
   "outputs": [],
   "source": [
    "# let's look more into year built vs type \n",
    "plt.plot(pd_train.yearbuilt, pd_train.buildingqualitytypeid, 'ro')\n",
    "# display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_647tI5Lp94v"
   },
   "source": [
    "### Final adjustments\n",
    "- filling nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofZIC0EdKJ0Y"
   },
   "source": [
    "# -----current: test ready-----\n",
    "- converting to pandas \n",
    "  - to see what's going on\n",
    "    - figuring out what can and what can't be replicated in cuML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4A3-sjRp8AE"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "# from cuml.preprocessing.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV,train_test_split\n",
    "#location seems to be related to building quality, (knnclassifier)\n",
    "\n",
    "def fillna_knn(df, base, target):\n",
    "    data_colnames = [target] + base\n",
    "    #print(\"data_colnames\",data_colnames)\n",
    "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
    "    #print(\"miss\",missing_values_boolflag.head())\n",
    "    not_missing_boolflag = ~missing_values_boolflag \n",
    "    #print(\"not miss\",not_missing_boolflag.head())\n",
    "    number_of_missing_val = missing_values_boolflag.sum()\n",
    "    print(\"# of miss\",number_of_missing_val)\n",
    "    not_missing_rows = df.loc[not_missing_boolflag, data_colnames]\n",
    "    #print(not_missing_rows.head())\n",
    "    Y = not_missing_rows[target]\n",
    "    X = not_missing_rows[base]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=3192,\n",
    "                                                        stratify=Y)\n",
    "    metrics       = ['euclidean'] \n",
    "    weights       = ['distance'] \n",
    "    numNeighbors  = [5,10,15,20,25]\n",
    "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
    "    cv            = StratifiedKFold(n_splits=3,random_state=3192,shuffle=False)\n",
    "    grid = GridSearchCV(neighbors.KNeighborsClassifier(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='f1_weighted',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "    grid.fit(X_train ,Y_train)\n",
    "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
    "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
    "    print(\"grid.best_params_\",grid.best_params_)\n",
    "    print(\"grid.scorer_\",grid.scorer_)\n",
    "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
    "    y_true, y_pred = Y_test, grid.predict(X_test)\n",
    "    \n",
    "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
    "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "AT8Osn51lD9v",
    "outputId": "8ab0690a-2e06-468e-b7ce-f4d051a3ce83"
   },
   "outputs": [],
   "source": [
    "print('CURRENT DF SITUATION\\n')\n",
    "\n",
    "print(f'SHAPE = {df_train.shape}')\n",
    "print(f'NULL COUNT = {df_train.buildingqualitytypeid.isnull().sum()}\\nVALUE COUNTS\\n{df_train.buildingqualitytypeid.value_counts()}\\n')\n",
    "\n",
    "df_train['buildingqualitytypeid'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "79bB7JKdAEtX",
    "outputId": "32b79160-fd19-4d39-988a-fc5fcd7c3284"
   },
   "outputs": [],
   "source": [
    "df_train['buildingqualitytypeid'] = df_train['buildingqualitytypeid'].fillna(-1)\n",
    "\n",
    "print(f'NULL COUNT = {df_train.buildingqualitytypeid.isnull().sum()}\\nVALUE COUNTS\\n{df_train.buildingqualitytypeid.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVgF1c_p_bN1"
   },
   "source": [
    "# -----current: break-----\n",
    "- break 1 of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "colab_type": "code",
    "id": "6eES-hq--NKZ",
    "outputId": "2bc86856-507d-47bf-cfab-d29649cba819"
   },
   "outputs": [],
   "source": [
    "# make safe copy\n",
    "test = df_train.copy()\n",
    "df_train = test.copy()\n",
    "# switch to pandas (figuring out what's going on)\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "id": "mAB9bsrPAGzQ",
    "outputId": "d847758e-212e-4de8-85c4-89b469b71c48"
   },
   "outputs": [],
   "source": [
    "# say we run this whole thing by buildingqualitytypeid\n",
    "# drop building types that aren't seen at least 3 times in the data\n",
    "# df_train = df_train.groupby(\"buildingqualitytypeid\").filter(lambda x: x.buildingqualitytypeid.size > 3)\n",
    "\n",
    "# BACK TO cuDF\n",
    "df_train = cudf.from_pandas(df_train)\n",
    "\n",
    "print(df_train.buildingqualitytypeid.value_counts())\n",
    "print()\n",
    "print(df_train.buildingqualitytypeid.isnull().sum())\n",
    "print(df_train.shape)\n",
    "print()\n",
    "\n",
    "type_ids = list(set(df_train.buildingqualitytypeid.values))\n",
    "from time import sleep\n",
    "safe = []\n",
    "for tid in type_ids:\n",
    "  print(tid)\n",
    "  sleep(5)\n",
    "  t = len(df_train.loc[df_train.buildingqualitytypeid == tid])\n",
    "  if t > 3:\n",
    "    safe.append(tid)\n",
    "  else:\n",
    "    print(f'{tid} count too low @ {t}')\n",
    "for tid in type_ids:\n",
    "  if tid not in safe:\n",
    "    df_train = df_train.loc[df_train.buildingqualitytypeid != tid]\n",
    "\n",
    "print()\n",
    "print(df_train.buildingqualitytypeid.value_counts())\n",
    "print()\n",
    "\n",
    "df_train['buildingqualitytypeid'] = df_train['buildingqualitytypeid'].replace(-1,np.nan)\n",
    "print(df_train.buildingqualitytypeid.isnull().sum())\n",
    "print(df_train.shape)\n",
    "\n",
    "# BACK TO PANDAS\n",
    "df_train = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zl7eXGt_g1uU"
   },
   "source": [
    "# -----current: break-----\n",
    "- break 2 of 2\n",
    "  - below is last cell run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "Q3ZBSOHm-79A",
    "outputId": "e9ddb9b3-0bb0-4cf7-fa8e-ca35b9ea7f46"
   },
   "outputs": [],
   "source": [
    "# run cell above (currently broken) as would be in pandas\n",
    "not_df_train = df_train.to_pandas()\n",
    "not_df_train = not_df_train.groupby(\"buildingqualitytypeid\").filter(lambda x: x.buildingqualitytypeid.size > 3)\n",
    "\n",
    "missing_values = fillna_knn(not_df_train, \n",
    "                            base = ['latitude', 'longitude'], \n",
    "                            target = 'buildingqualitytypeid')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = not_df_train['buildingqualitytypeid'].isnull()\n",
    "not_df_train.loc[missing_values_boolflag, 'buildingqualitytypeid'] = missing_values\n",
    "\n",
    "print(not_df_train.buildingqualitytypeid.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgXh5OATEacY"
   },
   "source": [
    "# BELOW NOT (really) RUN\n",
    "- if run, was in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "oTh_XPErqkHf",
    "outputId": "3e667bca-70c5-4b66-c7d2-12d171cb140b"
   },
   "outputs": [],
   "source": [
    "print(df_train.heating_system_id.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['heating_system_id']=temp['heating_system_id'].fillna(-1)\n",
    "temp=temp.groupby(\"heating_system_id\").filter(lambda x: x.heating_system_id.size > 3)\n",
    "temp['heating_system_id'] = temp['heating_system_id'].replace(-1,np.nan)\n",
    "print(temp.heating_system_id.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'heating_system_id')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['heating_system_id'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'heating_system_id' ]  = missing_values\n",
    "\n",
    "\n",
    "print(df_train.heating_system_id.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "oVjNSkUYqnCt",
    "outputId": "80fc7e87-36cd-44b7-96e9-ef0631c7d10c"
   },
   "outputs": [],
   "source": [
    "print(df_train.ac_id.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['ac_id']=temp['ac_id'].fillna(-1)\n",
    "temp=temp.groupby(\"ac_id\").filter(lambda x: x.ac_id.size > 3)\n",
    "temp['ac_id'] = temp['ac_id'].replace(-1,np.nan)\n",
    "print(temp.ac_id.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'ac_id')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['ac_id'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'ac_id' ]  = missing_values\n",
    "\n",
    "print(df_train.ac_id.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "qTbcYbexqr0Y",
    "outputId": "3459affa-a41a-4241-ab62-f0dfcadda039"
   },
   "outputs": [],
   "source": [
    "#yearbuilt\n",
    "print(df_train.yearbuilt.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['yearbuilt']=temp['yearbuilt'].fillna(-1)\n",
    "temp=temp.groupby(\"yearbuilt\").filter(lambda x: x.yearbuilt.size > 3)\n",
    "temp['yearbuilt'] = temp['yearbuilt'].replace(-1,np.nan)\n",
    "print(temp.yearbuilt.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude','buildingqualitytypeid','propertylandusetypeid' ] ,\n",
    "                  target = 'yearbuilt')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['yearbuilt'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'yearbuilt' ]  = missing_values\n",
    "print(df_train.yearbuilt.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx1LYGmfqxLk"
   },
   "outputs": [],
   "source": [
    "#location seems to be related to building quality, (knnregressor)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fillna_knnr( df, base, target):\n",
    "    data_colnames = [ target ] + base\n",
    "    #print(\"data_colnames\",data_colnames)\n",
    "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
    "    #print(\"miss\",missing_values_boolflag.head())\n",
    "    not_missing_boolflag = ~missing_values_boolflag \n",
    "    #print(\"not miss\",not_missing_boolflag.head())\n",
    "    number_of_missing_val = missing_values_boolflag.sum()\n",
    "    print(\"# of miss\",number_of_missing_val)\n",
    "    not_missing_rows = df.loc[ not_missing_boolflag, data_colnames]\n",
    "    #print(not_missing_rows.head())\n",
    "    Y = not_missing_rows[target]\n",
    "    X = not_missing_rows[base]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=3192)\n",
    "    metrics       = ['euclidean'] \n",
    "    weights       = ['distance'] \n",
    "    numNeighbors  = [5,10,15,20,25]\n",
    "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
    "    cv            = KFold(n_splits=3,random_state=3192,shuffle=False) \n",
    "    grid = GridSearchCV(neighbors.KNeighborsRegressor(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='neg_mean_absolute_error',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "    grid.fit(X_train ,Y_train)\n",
    "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
    "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
    "    print(\"grid.best_params_\",grid.best_params_)\n",
    "    print(\"grid.scorer_\",grid.scorer_)\n",
    "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
    "    y_true, y_pred = Y_test, grid.predict(X_test) \n",
    "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
    "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "pj5PXm7ozg5l",
    "outputId": "3d42279f-221c-444c-8795-05a0832f97cd"
   },
   "outputs": [],
   "source": [
    "#garage_sqft\n",
    "print(df_train.garage_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.loc[df_train.garagecarcnt>0,df_train.columns].copy()\n",
    "\n",
    "print(temp.garage_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = [ 'latitude', 'longitude','garagecarcnt'] ,\n",
    "                  target = 'garage_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['garage_sqft'].isnull()\n",
    "df_train.loc[missing_values_boolflag, 'garage_sqft'] = missing_values\n",
    "print(df_train.garage_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7e5CFTyzg_M"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop('parcelid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxGquCOOzhD7"
   },
   "outputs": [],
   "source": [
    "#All the other columns with missing values seems to be  integer, will need regression to be imputed,\n",
    "#time to get categorical variables hot encoded\n",
    "\n",
    "#Identify numerical columns to produce a heatmap\n",
    "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips', 'heating_system_id','has_hottub_or_spa',\n",
    "          'just_hottub_or_spa', 'pool_with_spa_tub_yes','pool_with_spa_tub_no','propertylandusetypeid','basement_flag'\n",
    "          ,'fireplaceflag','taxdelinquencyflag']\n",
    "numcols = [x for x in df_train.columns if x not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVZkszJEzhHj"
   },
   "outputs": [],
   "source": [
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_finished_living_area_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_finished_living_area_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = [ 'latitude', 'longitude','basementsqft','numberofstories','poolcnt','garagecarcnt','garage_sqft','propertylandusetypeid'] ,\n",
    "                  target = 'total_finished_living_area_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_finished_living_area_sqft'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_finished_living_area_sqft' ] = missing_values\n",
    "print(df_train.total_finished_living_area_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVrTMb92zhLX"
   },
   "outputs": [],
   "source": [
    "#total_bath\t1165\n",
    "#full_bath\t1182\n",
    "#half_bath\t1182\n",
    "#roomcnt\t1416\n",
    "#bedroomcnt\t1421\n",
    "\n",
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_bath.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_bath.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
    "                  target = 'total_bath')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_bath'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
    "print(df_train.total_bath.isnull().sum())#total_bath\t1165\n",
    "#full_bath\t1182\n",
    "#half_bath\t1182\n",
    "#roomcnt\t1416\n",
    "#bedroomcnt\t1421\n",
    "\n",
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_bath.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_bath.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
    "                  target = 'total_bath')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_bath'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
    "print(df_train.total_bath.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjIKlu-tzhPI"
   },
   "outputs": [],
   "source": [
    "# rop half_bath and full bath, as there are only redundant values of total_bath\n",
    "df_train = df_train.drop(['full_bath','half_bath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02X1y6EBzhT9"
   },
   "outputs": [],
   "source": [
    "#bedroomcnt\t1421\n",
    "\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.bedroomcnt.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft','total_bath' ] ,\n",
    "                  target = 'bedroomcnt')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['bedroomcnt'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'bedroomcnt' ] = missing_values\n",
    "print(df_train.bedroomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzkZ_qeHzhXP"
   },
   "outputs": [],
   "source": [
    "df_train['total_bath']=df_train.total_bath.round(1)\n",
    "df_train['bedroomcnt']=df_train.bedroomcnt.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF9DtDAczhaW"
   },
   "outputs": [],
   "source": [
    "#recalculate roomcnt\t1416 as we have used imputation for total_bath and bedroomcnt\n",
    "\n",
    "df_train.loc[(df_train.roomcnt.isnull()),['roomcnt']]=df_train.total_bath + df_train.bedroomcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5N41TBlz60W"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "df_train =df_train.loc[(df_train.total_parcel_tax.notnull()) & (df_train.land_tax.notnull()),df_train.columns]\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv9h5yL3z64Q"
   },
   "outputs": [],
   "source": [
    "#lot_area_sqft\n",
    "print(df_train.lot_area_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.lot_area_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'lot_area_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['lot_area_sqft'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'lot_area_sqft' ] = missing_values.round(2)\n",
    "print(df_train.lot_area_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYJLHrR4z68f"
   },
   "outputs": [],
   "source": [
    "# predict structure_tax and recalculate  total_parcel_tax = land_tax + structure_tax\n",
    "\n",
    "\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.structure_tax.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'structure_tax')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['structure_tax'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'structure_tax' ] = missing_values.round(2)\n",
    "print(df_train.structure_tax.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya-3K06Zz6_y"
   },
   "outputs": [],
   "source": [
    "#36 total_property_tax_2016 \n",
    "\n",
    "#total_parcel_tax = land_tax + structure_tax\n",
    "    \n",
    "df_train['total_parcel_tax']=df_train['structure_tax']+df_train['land_tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fvr7voVz7DX"
   },
   "outputs": [],
   "source": [
    "#age of the property\n",
    "df_train['age'] = 2016 - df_train['yearbuilt']\n",
    "df_train=df_train.drop(['yearbuilt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xl0EOIT-z7Gl"
   },
   "outputs": [],
   "source": [
    "#total_property_tax_2016\n",
    "\n",
    "\n",
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_property_tax_2016.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'total_property_tax_2016')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_property_tax_2016'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_property_tax_2016' ] = missing_values.round(2)\n",
    "print(df_train.total_property_tax_2016.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlaxWegqz7I-"
   },
   "outputs": [],
   "source": [
    "#check missing values\n",
    "\n",
    "missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.loc[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "print(missing_df)\n",
    "print(missing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIl_nqKVz7NQ"
   },
   "outputs": [],
   "source": [
    "#both the columns above miss 92% of the data, there is no related varibale to impute it, hence dropping them at this point\n",
    "\n",
    "df_train = df_train.drop(['finished_living_area_entryfloor_sqft2','finished_living_area_entryfloor_sqft1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQJd7rgKz7Qq"
   },
   "outputs": [],
   "source": [
    "#Identify numerical columns to produce a heatmap\n",
    "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips','pool_with_spa_tub_no','pool_with_spa_tub_yes','has_hottub_or_spa',\n",
    "           'just_hottub_or_spa','heating_system_id','propertylandusetypeid','basement_flag','fireplaceflag','taxdelinquencyflag']\n",
    "numcols = [x for x in df_train.columns if x not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUN3a6uJz7Ut"
   },
   "outputs": [],
   "source": [
    "# 2 variables are in object datatype, coverting into numeric\n",
    "df_train[['census_tractnumber','block_number']] = df_train[['census_tractnumber','block_number']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGx77rRAz7ZZ"
   },
   "outputs": [],
   "source": [
    "# dropping categorical columns as xgboost feature selection cannot hadle it\n",
    "\n",
    "train_x = df_train.drop(catcols+['logerror'], axis=1)\n",
    "\n",
    "train_y=df_train['logerror']\n",
    "\n",
    "train_x = train_x.astype(float) \n",
    "train_y = train_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "es_Ew2YJz7dT"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 65\n",
    "\n",
    "dtype_df = train_x.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
    "#dtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvWIhR38z7fW"
   },
   "outputs": [],
   "source": [
    "df_train.loc[df_train.has_hottub_or_spa==True,'has_hottub_or_spa']=\"Yes\"\n",
    "df_train.loc[df_train.has_hottub_or_spa==0,'has_hottub_or_spa']=\"No\"\n",
    "\n",
    "df_train.loc[df_train.just_hottub_or_spa==0,'just_hottub_or_spa']=\"No\"\n",
    "df_train.loc[df_train.just_hottub_or_spa==1,'just_hottub_or_spa']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.deck_flag==0,'deck_flag']=\"No\"\n",
    "df_train.loc[df_train.deck_flag==1,'deck_flag']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.basement_flag==0,'basement_flag']=\"No\"\n",
    "df_train.loc[df_train.basement_flag==1,'basement_flag']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.fireplaceflag==False,'fireplaceflag']=\"No\"\n",
    "df_train.loc[df_train.fireplaceflag==True,'fireplaceflag']=\"Yes\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ef9JjrmMz7jw"
   },
   "outputs": [],
   "source": [
    "#ac_id,heating_system_id,propertylandusetypeid\n",
    "dummieslist=['has_hottub_or_spa','just_hottub_or_spa',\n",
    "             'deck_flag','fips','basement_flag','fireplaceflag','taxdelinquencyflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z51Zrt2Uz7oD"
   },
   "outputs": [],
   "source": [
    "df_train[dummieslist] = df_train[dummieslist].astype(object)\n",
    "dummies = pd.get_dummies(df_train[dummieslist], prefix= dummieslist)\n",
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHBi5Gg6z7tu"
   },
   "outputs": [],
   "source": [
    "dummies2=['pool_with_spa_tub_no','pool_with_spa_tub_yes']\n",
    "df_train[dummies2] = df_train[dummies2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oocTPKI9z7rk"
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "from sqlalchemy import create_engine\n",
    "engineString = 'mysql+mysqldb://root:MyNewPass@localhost/sakila'\n",
    "engine = create_engine(engineString)\n",
    "con=engine.connect()\n",
    "\n",
    "with engine.connect() as con, con.begin():\n",
    "    df_train.to_sql('df_train_f1', engine, chunksize=10000, index =False,if_exists ='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zj5ZLSPlz7XC"
   },
   "outputs": [],
   "source": [
    "numcols2=['basementsqft','total_bath','bedroomcnt','total_finished_living_area_sqft','fireplace_count','garagecarcnt',\n",
    " 'garage_sqft','latitude','longitude','lot_area_sqft','poolcnt','pool_sqft','roomcnt','unitcnt','patio_sqft','storage_sqft',\n",
    " 'numberofstories','structure_tax','total_parcel_tax','land_tax','total_property_tax_2016','taxdelinquencyyear','transaction_month',\n",
    " 'census_tractnumber','block_number','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fp53dotszhgA"
   },
   "outputs": [],
   "source": [
    "Y=df_train['logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0Uaei4rzhj6"
   },
   "outputs": [],
   "source": [
    "#buildingqualitytypeid ->has order\n",
    "le = LabelEncoder()\n",
    "df_train['buildingqualitytypeid']=le.fit_transform(df_train.buildingqualitytypeid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4-g-uvtzhds"
   },
   "outputs": [],
   "source": [
    "#df_train.ac_id.value_counts()\n",
    "#df_train.propertylandusetypeid.value_counts()\n",
    "#'buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzliXafdzhRd"
   },
   "outputs": [],
   "source": [
    "X=pd.concat([dummies,df_train[dummies2],df_train[numcols2],df_train[['buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid']]],axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBsZjyQd0W1N"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=3192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihXFZWcn0W5D"
   },
   "outputs": [],
   "source": [
    "#  top features\n",
    "import xgboost as xgb\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    'seed' : 0\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train, Y_train, feature_names=X_train.columns.values)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "#max_num_features=50, error for no reason \n",
    "xgb.plot_importance(model, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQEEzNkX0W9w"
   },
   "outputs": [],
   "source": [
    "#top features\n",
    "xgboost_selection=['total_finished_living_area_sqft','latitude','structure_tax','total_property_tax_2016',\n",
    "'total_parcel_tax','land_tax','longitude','lot_area_sqft','census_tractnumber','age','total_bath','bedroomcnt',\n",
    "'block_number','transaction_month','roomcnt','taxdelinquencyyear','unitcnt','taxdelinquencyflag_No',\n",
    "'fips_LA','garage_sqft','pool_with_spa_tub_no','has_hottub_or_spa_No','garagecarcnt','deck_flag_No',\n",
    "'poolcnt','pool_sqft'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rr_6EO4G0XEj"
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#c_id,heating_system_id,propertylandusetypeid\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "reg = ExtraTreesRegressor(n_estimators=500, max_depth=8, max_features='sqrt',\n",
    "                          min_samples_split=100 ,min_samples_leaf=10, bootstrap=True,n_jobs=-1, random_state=3192)\n",
    "reg = reg.fit(X_train, Y_train)\n",
    "#print(\"importance\",reg.feature_importances_) \n",
    "model = SelectFromModel(reg, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_new.shape)  \n",
    "\n",
    "feat_names = X.columns.values\n",
    "importances = reg.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in reg.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1][:26]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4FCNOG70XIU"
   },
   "outputs": [],
   "source": [
    "tree_selection=[\n",
    "    'total_finished_living_area_sqft','structure_tax','total_property_tax_2016','total_bath','total_parcel_tax',\n",
    "    'age','latitude','census_tractnumber','bedroomcnt','longitude','land_tax','propertylandusetypeid','block_number',\n",
    "    'buildingqualitytypeid','numberofstories','heating_system_id','unitcnt','transaction_month','lot_area_sqft','roomcnt',\n",
    "    'garage_sqft','garagecarcnt','pool_with_spa_tub_no','poolcnt','fips_LA','taxdelinquencyyear','patio_sqft',\n",
    "    'taxdelinquencyflag_No','taxdelinquencyflag_Yes'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmIS1WAS0XMW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer\n",
    "\n",
    "#model=Lasso(alpha=0.2, fit_intercept=True, normalize=True, precompute=False, copy_X=True,\n",
    " #                                max_iter=1000, \n",
    "  #                               tol=0.0001, warm_start=False, positive=False, random_state=3192, selection='cyclic')\n",
    "\n",
    "#Ridge(random_state=3192,solver='auto',fit_intercept=True,normalize=True,alpha=0.1)\n",
    "#LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True)\n",
    "\n",
    "\n",
    "rfecv = RFECV(estimator=LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True), step=2, cv=KFold(4),scoring='neg_mean_absolute_error')\n",
    "rfecv.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIw8O00U0XPR"
   },
   "outputs": [],
   "source": [
    "rfe_selection = [i for indx,i in enumerate(X.columns) if rfecv.support_[indx] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHA0x5_80XWy"
   },
   "outputs": [],
   "source": [
    "#Linear regression with rfe_selection selection\n",
    "#rfe_selection, tree_selection, xgboost_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer,mean_squared_error\n",
    "\n",
    "# just to check whether normalized /not normalized data gives better results\n",
    "parameters = {'fit_intercept':[True], 'normalize':[True,False], 'copy_X':[True]}\n",
    "scoring = {'MAE':'neg_mean_absolute_error','MSE': make_scorer(mean_squared_error,greater_is_better=False)}\n",
    "\n",
    "grid1 = GridSearchCV(LinearRegression(n_jobs=-1),param_grid=parameters, scoring=scoring,cv=5,refit='MAE',\n",
    "                    return_train_score=True,\n",
    "                    verbose=0,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "\n",
    "grid1.fit(X_train[rfe_selection], Y_train)\n",
    "#print(\"5. grid best_score_\",abs(grid.best_score_))\n",
    "Y_pred = grid1.predict(X_test[rfe_selection])\n",
    "print(\"MAE on test data\",mean_absolute_error(Y_test,Y_pred))\n",
    "print(\"MSE on test data\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R Squared data \",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekn4pBs60XcT"
   },
   "outputs": [],
   "source": [
    "#pca selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "scaled_x = scale(X)\n",
    "pca = PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFuT-wUN0XfV"
   },
   "outputs": [],
   "source": [
    "# The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPN4OBUe0XlD"
   },
   "outputs": [],
   "source": [
    "#Looking at above plot I'm taking 28 variables\n",
    "\n",
    "pca = PCA(n_components=28, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)\n",
    "\n",
    "pca1=pca.fit_transform(scaled_x)\n",
    "\n",
    "pca = PCA(n_components=28, copy=True, whiten=True, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)\n",
    "pca2=pca.fit_transform(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EE4ednPC0XjX"
   },
   "outputs": [],
   "source": [
    "pcaX_train, pcaX_test, pcaY_train, pcaY_test = train_test_split(pca1, Y, test_size=0.10, random_state=3192)\n",
    "pca2X_train, pca2X_test, pca2Y_train, pca2Y_test = train_test_split(pca2, Y, test_size=0.10, random_state=3192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erYMXvTG0XaK"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# just to check whether normalized /not normalized data gives better results\n",
    "\n",
    " # 0.005 for 1200 trees.\n",
    "param_grid={'n_estimators':[1200],'max_features':[22]}\n",
    "\n",
    "              \n",
    "grid13 = GridSearchCV(GradientBoostingRegressor(subsample=0.8,min_samples_leaf=50,min_samples_split=50,max_depth=9,loss='ls',criterion='friedman_mse',learning_rate=0.005,random_state=3192),\n",
    "                     param_grid=param_grid, cv=5,refit='MAE',\n",
    "                    return_train_score=True,\n",
    "                    verbose=2,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "\n",
    "grid13.fit(pcaX_train, pcaY_train)\n",
    "print(\"5. grid best_score_\",abs(grid13.best_score_))\n",
    "print(\"best params\",grid13.best_params_)\n",
    "print(\"best score\",grid13.best_score_)\n",
    "Y_pred = grid13.predict(pcaX_test)\n",
    "print(\"MAE on test data\",mean_absolute_error(pcaY_test,Y_pred))\n",
    "print(\"MSE on test data\",mean_squared_error(pcaY_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgtbLCcR0XUx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjdSCEFP0XCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzATgLxmam5w"
   },
   "source": [
    "In this competition, Zillow is asking you to predict the log-error between their Zestimate and the actual sale price, given all the features of a home. The log error is defined as\n",
    "\n",
    "logerror=log(Zestimate)−log(SalePrice)\n",
    "and it is recorded in the transactions file train.csv. In this competition, you are going to predict the logerror for the months in Fall 2017. Since all the real estate transactions in the U.S. are publicly available, we will close the competition (no longer accepting submissions) before the evaluation period begins.\n",
    "\n",
    "Train/Test split\n",
    "You are provided with a full list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) data in 2016.\n",
    "The train data has all the transactions before October 15, 2016, plus some of the transactions after October 15, 2016.\n",
    "The test data in the public leaderboard has the rest of the transactions between October 15 and December 31, 2016.\n",
    "The rest of the test data, which is used for calculating the private leaderboard, is all the properties in October 15, 2017, to December 15, 2017. This period is called the \"sales tracking period\", during which we will not be taking any submissions.\n",
    "You are asked to predict 6 time points for all properties: October 2016 (201610), November 2016 (201611), December 2016 (201612), October 2017 (201710), November 2017 (201711), and December 2017 (201712).\n",
    "Not all the properties are sold in each time period. If a property was not sold in a certain time period, that particular row will be ignored when calculating your score.\n",
    "If a property is sold multiple times within 31 days, we take the first reasonable value as the ground truth. By \"reasonable\", we mean if the data seems wrong, we will take the transaction that has a value that makes more sense.\n",
    "File descriptions\n",
    "properties_2016.csv - all the properties with their home features for 2016. Note: Some 2017 new properties don't have any data yet except for their parcelid's. Those data points should be populated when properties_2017.csv is available.\n",
    "properties_2017.csv - all the properties with their home features for 2017 (released on 10/2/2017)\n",
    "train_2016.csv - the training set with transactions from 1/1/2016 to 12/31/2016\n",
    "train_2017.csv - the training set with transactions from 1/1/2017 to 9/15/2017 (released on 10/2/2017)\n",
    "sample_submission.csv - a sample submission file in the correct format"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "zillow_kaggle_zestimate_comp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
