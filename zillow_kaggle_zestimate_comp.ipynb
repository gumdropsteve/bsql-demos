{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scfLT2i0MLyD"
   },
   "source": [
    "# Environment Sanity Check #\n",
    "\n",
    "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
    "\n",
    "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4.\n",
    "\n",
    "#Setup:\n",
    "\n",
    "1. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n",
    "2. Install RAPIDS libraries\n",
    "3. Set necessary environment variables\n",
    "4. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions\n",
    "- **TLDR**\n",
    "  - Hit `Shift` + `Enter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "W-um5d-x7o46",
    "outputId": "a604e66b-95d7-44fb-f8d3-848fcedaf796"
   },
   "outputs": [],
   "source": [
    "# \"\"\"make sure we have the right GPU\n",
    "# > column 1 row 3 == Tesla T4\n",
    "# \"\"\"\n",
    "# # display gpu specs\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkEdr1VmigyU"
   },
   "source": [
    "### Install RAPIDS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p129YxxnihcV"
   },
   "outputs": [],
   "source": [
    "# !wget -nc https://raw.githubusercontent.com/rapidsai/notebooks-contrib/master/utils/rapids-colab.sh\n",
    "# # RAPIDS 0.10 nightly\n",
    "# !bash rapids-colab.sh \n",
    "\n",
    "# import sys, os\n",
    "\n",
    "# sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
    "# os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
    "# os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CsdVW7SU9Li"
   },
   "source": [
    "# Zillow Kaggle Competition on RAPIDS AI\n",
    "- initially based off eswar3's [Zillow prediction models]( https://github.com/eswar3/Zillow-prediction-models) repo\n",
    "## Download Data\n",
    "- to download the data, please plug in your kaggle api username & key\n",
    "  - you can set up your kaggle api at `https://www.kaggle.com/YOUR USERNAME HERE/account`\n",
    "  - learn more: https://github.com/Kaggle/kaggle-api#api-credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1dLRTm168Tk"
   },
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !mkdir /root/.kaggle\n",
    "\n",
    "# # plug api -- get your own API key\n",
    "# !echo '{\"username\":\"warobson\", \"key\":\"0cf106a008ccb1fbdd5c6c4f190bb4b8\"}' > /root/.kaggle/kaggle.json\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# # !kaggle datasets download\n",
    "# !kaggle competitions download -c zillow-prize-1\n",
    "\n",
    "# # unzip kaggle data\n",
    "# !unzip -q \"/content/sample_submission.csv.zip\"\n",
    "# !unzip -q \"/content/train_2016_v2.csv.zip\"\n",
    "# !unzip -q \"/content/properties_2016.csv.zip\"\n",
    "# !unzip -q \"/content/train_2017.csv.zip\"\n",
    "# !unzip -q \"/content/properties_2017.csv.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LICr9uz8do9K"
   },
   "source": [
    "#### How is the data saved?\n",
    "- inside content directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "6n75DyJ-dm4B",
    "outputId": "64ac687e-39d6-4bb1-f4b7-5476c9de3b84"
   },
   "outputs": [],
   "source": [
    "# # display content folder contents\n",
    "# !ls \"/content/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lpa1b4edIXuT"
   },
   "source": [
    "# Imports\n",
    "### RAPIDS\n",
    "* `cuDf`\n",
    "  - words here\n",
    "* `cuML`\n",
    "  - words here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKN5zuROroJD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "# rapids \n",
    "import cudf, cuml \n",
    "from blazingsql import BlazingContext\n",
    "bc = BlazingContext(pool=False)\n",
    "\n",
    "# switch to cupy next update (once docker has it)\n",
    "import numpy as np\n",
    "\n",
    "# general \n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJeywzd2efw7"
   },
   "source": [
    "## Data\n",
    "* `properties_2016`\n",
    "  - aprox. 27,000,000 residential properties \n",
    "  - 58 attributes each\n",
    "* `train_2016_v2`\n",
    "  - 90,000 transaction records for closings in the year 2016\n",
    "    * Merge datasets on `property_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "2EfApIzCfEtr",
    "outputId": "bc1e37d1-9ab8-4561-fa39-5af420480a72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>decktypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>650756.0</td>\n",
       "      <td>1413387.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>762631.0</td>\n",
       "      <td>20800.37</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid airconditioningtypeid architecturalstyletypeid basementsqft  \\\n",
       "0  10754147                  null                     null         null   \n",
       "1  10759547                  null                     null         null   \n",
       "2  10843547                  null                     null         null   \n",
       "\n",
       "   bathroomcnt  bedroomcnt buildingclasstypeid buildingqualitytypeid  \\\n",
       "0          0.0         0.0                null                  null   \n",
       "1          0.0         0.0                null                  null   \n",
       "2          0.0         0.0                null                  null   \n",
       "\n",
       "  calculatedbathnbr decktypeid  ... numberofstories fireplaceflag  \\\n",
       "0              null       null  ...            null          null   \n",
       "1              null       null  ...            null          null   \n",
       "2              null       null  ...            null          null   \n",
       "\n",
       "  structuretaxvaluedollarcnt taxvaluedollarcnt assessmentyear  \\\n",
       "0                       null               9.0         2015.0   \n",
       "1                       null           27516.0         2015.0   \n",
       "2                   650756.0         1413387.0         2015.0   \n",
       "\n",
       "   landtaxvaluedollarcnt  taxamount  taxdelinquencyflag taxdelinquencyyear  \\\n",
       "0                    9.0       null                None               null   \n",
       "1                27516.0       null                None               null   \n",
       "2               762631.0   20800.37                None               null   \n",
       "\n",
       "  censustractandblock  \n",
       "0                null  \n",
       "1                null  \n",
       "2                null  \n",
       "\n",
       "[3 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag data directory\n",
    "data_dir = f'{os.getcwd()}/zillow_data'\n",
    "\n",
    "# import 2016 properties\n",
    "bc.create_table('prop2016', f'{data_dir}/properties_2016.csv', header=0)\n",
    "# prop2016 = cudf.read_csv('zillow_data/properties_2016.csv')\n",
    "\n",
    "# peek display 2016 properties\n",
    "bc.sql('select * from prop2016').head(3)\n",
    "# prop2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "uynoUxpx8Xsn",
    "outputId": "b64b7b32-c1f9-4cf3-c50d-36e90dc51a64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate\n",
       "0  11016594    0.0276      2016-01-01\n",
       "1  14366692   -0.1684      2016-01-01\n",
       "2  12098116   -0.0040      2016-01-01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import train 2016  data\n",
    "bc.create_table('train2016', f'{data_dir}/train_2016_v2.csv', header=0, parse_dates=[\"transactiondate\"])\n",
    "# train2016 = cudf.read_csv('zillow_data/train_2016_v2.csv',\n",
    "#                           parse_dates=[\"transactiondate\"])\n",
    "\n",
    "# peek display 2016 train\n",
    "bc.sql('select * from train2016').head(3)\n",
    "# train2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGiscxESJDrl"
   },
   "source": [
    "## [Zillow Prediction Model](https://colab.research.google.com/github/eswar3/Zillow-prediction-models/blob/master/Step%202a-Approach1.ipynb)\n",
    "\n",
    "    In this approach the properties data and transaction data are merged together before adressing any missing values\n",
    "\n",
    "\n",
    "#### Merging Data \n",
    " - we will start by merging the two dataframes\n",
    "  - then rename the new dataframe's attributes to be meaningful \n",
    "    - e.g. from `pooltypeid7` to `pool_with_spa_tub_no` and `structuretaxvaluedollarcnt` to `structure_tax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyblazing.apiv2.context.BlazingTable at 0x7f3ca0010350>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_query = '''\n",
    "             SELECT \n",
    "                 p.*,\n",
    "                 t.logerror, t.transactiondate\n",
    "             FROM \n",
    "                 prop2016 AS p\n",
    "                 LEFT JOIN \n",
    "                     train2016 AS t\n",
    "                         ON (p.parcelid = t.parcelid)\n",
    "                         '''\n",
    "\n",
    "bc.create_table('full_2016', bc.sql(join_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>ac_id</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basement_sqft</th>\n",
       "      <th>total_bath</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>deck_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>structure_tax</th>\n",
       "      <th>total_parcel_tax</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>land_tax</th>\n",
       "      <th>total_property_tax_2016</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2985337</th>\n",
       "      <td>12955207</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>101648.0</td>\n",
       "      <td>276558.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>174910.0</td>\n",
       "      <td>3412.27</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>6.037408e+13</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985338</th>\n",
       "      <td>12955353</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>null</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>103651.0</td>\n",
       "      <td>140826.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>37175.0</td>\n",
       "      <td>1934.40</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>6.037408e+13</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985339</th>\n",
       "      <td>12955522</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>null</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>138580.0</td>\n",
       "      <td>183554.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>44974.0</td>\n",
       "      <td>2399.19</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>6.037408e+13</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985340</th>\n",
       "      <td>12955783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>null</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>403000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>183000.0</td>\n",
       "      <td>4948.95</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>6.037408e+13</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985341</th>\n",
       "      <td>12955837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>null</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>null</td>\n",
       "      <td>...</td>\n",
       "      <td>92906.0</td>\n",
       "      <td>201839.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>108933.0</td>\n",
       "      <td>2440.68</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>6.037408e+13</td>\n",
       "      <td>null</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parcelid ac_id architecturalstyletypeid basement_sqft  total_bath  \\\n",
       "2985337  12955207  null                     null          null         2.0   \n",
       "2985338  12955353  null                     null          null         2.0   \n",
       "2985339  12955522  null                     null          null         3.0   \n",
       "2985340  12955783   1.0                     null          null         3.0   \n",
       "2985341  12955837   1.0                     null          null         2.0   \n",
       "\n",
       "         bedroomcnt buildingclasstypeid  buildingqualitytypeid  \\\n",
       "2985337         2.0                null                    4.0   \n",
       "2985338         3.0                null                    4.0   \n",
       "2985339         4.0                null                    4.0   \n",
       "2985340         4.0                null                    4.0   \n",
       "2985341         3.0                null                    7.0   \n",
       "\n",
       "         calculatedbathnbr deck_flag  ... structure_tax total_parcel_tax  \\\n",
       "2985337                2.0      null  ...      101648.0         276558.0   \n",
       "2985338                2.0      null  ...      103651.0         140826.0   \n",
       "2985339                3.0      null  ...      138580.0         183554.0   \n",
       "2985340                3.0      null  ...      220000.0         403000.0   \n",
       "2985341                2.0      null  ...       92906.0         201839.0   \n",
       "\n",
       "         assessmentyear  land_tax  total_property_tax_2016  \\\n",
       "2985337          2015.0  174910.0                  3412.27   \n",
       "2985338          2015.0   37175.0                  1934.40   \n",
       "2985339          2015.0   44974.0                  2399.19   \n",
       "2985340          2015.0  183000.0                  4948.95   \n",
       "2985341          2015.0  108933.0                  2440.68   \n",
       "\n",
       "         taxdelinquencyflag  taxdelinquencyyear censustractandblock logerror  \\\n",
       "2985337                None                null        6.037408e+13     null   \n",
       "2985338                None                null        6.037408e+13     null   \n",
       "2985339                None                null        6.037408e+13     null   \n",
       "2985340                None                null        6.037408e+13     null   \n",
       "2985341                None                null        6.037408e+13     null   \n",
       "\n",
       "         transactiondate  \n",
       "2985337             None  \n",
       "2985338             None  \n",
       "2985339             None  \n",
       "2985340             None  \n",
       "2985341             None  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set colums to be renamed for general english understandability \n",
    "rename_these = {\"bathroomcnt\": \"total_bath\",\n",
    "                \"fullbathcnt\": \"full_bath\",\n",
    "                \"threequarterbathnbr\": \"half_bath\",\n",
    "                \"yardbuildingsqft17\": \"patio_sqft\",\n",
    "                \"yardbuildingsqft26\":\"storage_sqft\",\n",
    "                \"decktypeid\": \"deck_flag\",\n",
    "                \"pooltypeid7\": \"pool_with_spa_tub_no\", \n",
    "                \"pooltypeid2\": \"pool_with_spa_tub_yes\",\n",
    "                \"hashottuborspa\": \"has_hottub_or_spa\", \n",
    "                \"pooltypeid10\": \"just_hottub_or_spa\",\n",
    "                \"calculatedfinishedsquarefeet\":\"total_finished_living_area_sqft\", \n",
    "                \"finishedsquarefeet12\": \"finished_living_area_sqft\",\n",
    "                \"lotsizesquarefeet\": \"lot_area_sqft\",\n",
    "                \"finishedsquarefeet50\":\"finished_living_area_entryfloor_sqft1\",\n",
    "                \"finishedfloor1squarefeet\":\"finished_living_area_entryfloor_sqft2\",\n",
    "                \"finishedsquarefeet6\": \"base_unfinished_and_finished_area_sqft\",\n",
    "                \"finishedsquarefeet15\": \"total_area_sqft\",\n",
    "                \"finishedsquarefeet13\": \"preimeter_living_area_sqft\",\n",
    "                \"taxvaluedollarcnt\": \"total_parcel_tax\",\n",
    "                \"landtaxvaluedollarcnt\": \"land_tax\",\n",
    "                \"taxamount\":\"total_property_tax_2016\",\n",
    "                \"structuretaxvaluedollarcnt\":\"structure_tax\",\n",
    "                \"garagetotalsqft\": \"garage_sqft\",\n",
    "                \"fireplacecnt\": \"fireplace_count\",\n",
    "                \"buildingqualitytypeid \": \"building_quality_id\",\n",
    "                \"heatingorsystemtypeid\": \"heating_system_id\",\n",
    "                \"airconditioningtypeid\": \"ac_id\",\n",
    "                \"storytypeid\": \"basement_flag\",\n",
    "                \"basementsqft\": \"basement_sqft\",\n",
    "                \"poolsizesum\": \"pool_sqft\",\n",
    "                \"poolcnt\": \"pool_count\"}\n",
    "\n",
    "# rename columns & add transaction month column\n",
    "df_train = bc.sql('select * from full_2016').rename(columns=rename_these)\n",
    "\n",
    "# what's the data frame look like?\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdtyBI2jFnJv"
   },
   "source": [
    "## Conforming Attribute Values\n",
    "### #0 boolean columns & null = 0s cases \n",
    "* `pool_count`, `pool_with_spa_tub_no` and `pool_with_spa_tub_yes` are all binary variables, replace all NULL values with zero\n",
    "*   `basement_flag` has values 7 & `Null` but is supposed to be bool, convert the `7`s to `1`s and the `Null`s to `0`s \n",
    "* patio and shed variables with null values are assumed to have none\n",
    "* deck_flag has only 2 values, `66` and `null`\n",
    "  - convert it into binary flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3bPdNONHTYI"
   },
   "outputs": [],
   "source": [
    "# replace missing pool count values so we booling\n",
    "the_bool_club = ['pool_count','pool_with_spa_tub_no','pool_with_spa_tub_yes',\n",
    "                 'basement_flag','patio_sqft','storage_sqft', 'deck_flag']\n",
    "\n",
    "for col in the_bool_club:\n",
    "  # convert null values to 0\n",
    "  df_train[col]=df_train[col].fillna(0)\n",
    "\n",
    "# convert 7s and 66s to 1s\n",
    "df_train['basement_flag'] = df_train['basement_flag'].replace(7, 1)\n",
    "df_train['deck_flag'] = df_train['deck_flag'].replace(66, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MbGy6r7JLLD"
   },
   "source": [
    "### #1 The pool\n",
    "*   When pool is present and if it has tub/spa then `just_hottub_or_spa` = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "B3-1V93smA9A",
    "outputId": "52e1a5d7-869a-443f-ac2d-40504992dc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.0    36941\n",
      "Name: just_hottub_or_spa, dtype: int32\n",
      "\n",
      "after\n",
      "1.0    36941\n",
      "0.0    32075\n",
      "Name: just_hottub_or_spa, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(f'before\\n{df_train.just_hottub_or_spa.value_counts()}\\n')\n",
    "\n",
    "# if poolcnt=1 and has_hottub_or_spa=1 and just_hottub_or_spa is null\n",
    "conditions = ((df_train['pool_count'] == 1) \n",
    "              & (df_train['has_hottub_or_spa'] == 1) \n",
    "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
    "# then just_hottub_or_spa = 0\n",
    "df_train.just_hottub_or_spa.loc[conditions] = 0\n",
    "\n",
    "print(f'after\\n{df_train.just_hottub_or_spa.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6E3-_XlSGBs"
   },
   "source": [
    "\n",
    "- when `has_hottub_or_spa` is null and `just_hottub_or_spa` is null\n",
    "  - both should be zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xa12WFccSGM6"
   },
   "outputs": [],
   "source": [
    "# if both has hottub and just hottub are null\n",
    "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
    "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
    "# just hottub or spa = 0 \n",
    "df_train.just_hottub_or_spa.loc[conditions] = 0\n",
    "\n",
    "# now, if has hottub is null and just hottub is 0 \n",
    "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
    "              & (df_train['just_hottub_or_spa'] == 0))\n",
    "# has hottub or spa = 0 \n",
    "df_train.has_hottub_or_spa.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5umCCWN73qxw"
   },
   "source": [
    "- when there is no pool\n",
    "  - if there is tub/spa \n",
    "    - then `just_hottub_or_spa`  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "FBgs7zJm3qk-",
    "outputId": "78c76ac5-2b7f-4f98-9615-8a335bc3214e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2948401\n",
       "1.0      36941\n",
       "Name: just_hottub_or_spa, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when poolcnt=0, has_hottub_or_spa=1\n",
    "conditions = ((df_train['pool_count'] == 0) \n",
    "              & (df_train['has_hottub_or_spa'] == 1))\n",
    "# just_hottub_or_spa=1\n",
    "df_train.just_hottub_or_spa.loc[conditions] = 1\n",
    "\n",
    "# let's check the values\n",
    "df_train.just_hottub_or_spa.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LsRr1aoSCVx"
   },
   "source": [
    "*   When there is no pool, set pool size to zero instead of na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtdyXCbx0TKx"
   },
   "outputs": [],
   "source": [
    "# where there is no pool\n",
    "conditions = df_train['pool_count']==0\n",
    "# square footage of non existant pool is 0 \n",
    "df_train.pool_sqft.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQFkXmAgQPY"
   },
   "source": [
    "### #2 The basement\n",
    "*    Where `basement_flag` is zero, `basement_sqft` should also be zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMuCOqAmLTmY"
   },
   "outputs": [],
   "source": [
    "# where there is no basement\n",
    "conditions = df_train['basement_flag'] == 0\n",
    "# fun fact: we just did this with the pool\n",
    "df_train.basement_sqft.loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU6Uohb-PDYB"
   },
   "source": [
    "### #3 The fireplace\n",
    "There seems to be inconsistency between the `fireplace_flag` and `fireplace_count`\n",
    "- 90,053 flag values are null\n",
    "- 80,688 `fireplace_count` values are null\n",
    "    * 9,385 (-11.5%) difference, but a boatload either way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OZM6lXmmpj5k",
    "outputId": "ecf62d1d-b036-41ad-8052-a3090ae590ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 2672695 fireplace_count nulls\n",
      "there are 2980177 fireplaceflag nulls\n"
     ]
    }
   ],
   "source": [
    "print(f\"there are {df_train['fireplace_count'].isna().sum()} fireplace_count \\\n",
    "nulls\\nthere are {df_train['fireplaceflag'].isna().sum()} fireplaceflag nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9ZAzFoIpkSF"
   },
   "source": [
    "* context driven solutions\n",
    "  * where neither flag nor count exists, `fireplaceflag == False`\n",
    "  *   when `fireplace_count` is more than zero `fireplaceflag` should be `True`\n",
    "  * if `fireplaceflag == False`, the `fireplace_count` is logically `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "i3YRZgU_qZhA",
    "outputId": "e45a7a96-2e1d-47d2-a0bd-48ece42cbb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5165 fireplace_count nulls\n",
      "there are 0 fireplaceflag nulls\n"
     ]
    }
   ],
   "source": [
    "# null flags with null counts are zero\n",
    "conditions = ((df_train['fireplace_count'].isna()==True) \n",
    "              & (df_train['fireplaceflag'].isna()==True))\n",
    "df_train.fireplaceflag.loc[conditions] = False\n",
    "\n",
    "# true flags for positive fireplace counts\n",
    "conditions = df_train['fireplace_count'] > 0\n",
    "df_train.fireplaceflag.loc[conditions] = True\n",
    "\n",
    "# set fireplace count nulls to 0 where false flags are\n",
    "conditions = ((df_train['fireplace_count'].isna()==True) \n",
    "              & (df_train['fireplaceflag']==False))\n",
    "df_train.fireplace_count.loc[conditions] = 0\n",
    "\n",
    "print(f\"there are {df_train['fireplace_count'].isna().sum()} fireplace_count \\\n",
    "nulls\\nthere are {df_train['fireplaceflag'].isna().sum()} fireplaceflag nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYntUejosOn3"
   },
   "source": [
    "### #4 The garage\n",
    "*   Properties with no garages would have NA values for both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9mGs-mK9E0Q"
   },
   "outputs": [],
   "source": [
    "garage = ['garagecarcnt', 'garage_sqft']\n",
    "# where garage car count and garage square feet are null\n",
    "conditions = ((df_train['garagecarcnt'].isna()==True) \n",
    "              & (df_train['garage_sqft'].isna()==True))\n",
    "# set both to 0\n",
    "df_train[garage].loc[conditions] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uV115W6-ohW"
   },
   "source": [
    "Exploring the data farther, we see\n",
    "- `garage_sqft` holds over 8,900 measurements of 0 despite the garage's car count being 1 or more  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "gbbUIbwJ-ouS",
    "outputId": "310a4cdf-01a0-4fc3-ed1b-0e2f5e668518"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>garage_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     garagecarcnt  garage_sqft\n",
       "0             1.0          0.0\n",
       "1             1.0          0.0\n",
       "2             1.0          0.0\n",
       "177           1.0          0.0\n",
       "576           2.0          0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show rows where garage count and square feet don't add up\n",
    "conditions = (df_train.garagecarcnt > 0) & (df_train.garage_sqft == 0)\n",
    "\n",
    "# give a display\n",
    "df_train.loc[conditions][garage].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5I1O76QKA8Cb"
   },
   "source": [
    "- these 0 values need to be null\n",
    " - because no garage holding 1 or more cars in 2016 measured 0sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWVtoty0A9Jt"
   },
   "outputs": [],
   "source": [
    "# where garage count and square feet don't add up\n",
    "conditions = (df_train.garagecarcnt>0) & (df_train.garage_sqft==0)\n",
    "# insert a NaN value\n",
    "df_train.garage_sqft.loc[conditions] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seb6r5wx5Bbz"
   },
   "source": [
    "### #5 The bath\n",
    "*   `total_bath` & `calculatedbathnbr` are near-duplicates w/ `calculated` having more nulls\n",
    "  - let's drop it\n",
    "*   if `full_bath` is null and `half_bath` is also null\n",
    "  - let's make `total_bath` = 0 \n",
    "      - because we can't truthfully assume it's any more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgMNToed5BMu"
   },
   "outputs": [],
   "source": [
    "# drop calculated bath column\n",
    "df_train = df_train.drop('calculatedbathnbr', axis=1)\n",
    "\n",
    "# if full_bath is null & half_bath is null\n",
    "conditions = ((df_train['full_bath'].isnull()==True) \n",
    "              & (df_train['half_bath'].isnull()==True) \n",
    "              & (df_train['total_bath']==0))\n",
    "# total_bath=0\n",
    "df_train.total_bath.loc[conditions] = np.nan\n",
    "\n",
    "# when full_bath==total_bath, half_bath=0 \n",
    "df_train.half_bath.loc[df_train.full_bath == df_train.total_bath] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sh8cG0pr4_hl"
   },
   "source": [
    "### #6 Mode Imputation \n",
    "* scaling down the latitude and longitide\n",
    "  - knn imput takes more time due to the larger numbers\n",
    "  - standardizing gives better results on most algorithms\n",
    "    - this is a competition, we came to win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kitrNxKgLWUd"
   },
   "outputs": [],
   "source": [
    "df_train['latitude'] = df_train.latitude / 100000\n",
    "df_train['longitude'] = df_train.longitude / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6bhRhu5YZ1d"
   },
   "source": [
    "### #7 numberofstories & unitcnt & roomcnt\n",
    "* we can devise unit count based on property land type\n",
    "  - so we can now go ahead and correct the unit counts for each given property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "yHZH4rMNLfBA",
    "outputId": "97106bb4-10f2-49a9-f821-03a3972db136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0      2757718\n",
       "2.0       123569\n",
       "4.0        40765\n",
       "3.0        40315\n",
       "5.0          588\n",
       "          ...   \n",
       "865.0          1\n",
       "883.0          1\n",
       "888.0          1\n",
       "951.0          1\n",
       "997.0          1\n",
       "Name: unitcnt, Length: 146, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where room count is 0, go ahead and NaN it\n",
    "df_train.roomcnt.loc[df_train['roomcnt'] == 0] = np.nan\n",
    "\n",
    "\"\"\"\n",
    "propertylandusetypeid & unitcnt are related \n",
    "  these are the propertylandusetypeid codes & their definitions\n",
    "  \n",
    "#246 -Duplex (2 Units, Any Combination)\n",
    "#247 -Triplex (3 Units, Any Combination)\n",
    "#248 -Quadruplex (4 Units, Any Combination)\n",
    "#260 -Residential General\n",
    "#261 -Single Family Residential\n",
    "#263 -Mobile Home\n",
    "#264 -Townhouse\n",
    "#266 -Condominium\n",
    "#267 -Cooperative\n",
    "#269 -Planned Unit Development\n",
    "#275 -Residential Common Area \n",
    "#31 - Commercial/Office/Residential Mixed Used\n",
    "#47 -Store/Office (Mixed Use)\n",
    "#265 -Cluster Home\n",
    "\"\"\"\n",
    "\n",
    "# one unit \n",
    "ones = [260,261,263,264,266,267,269,275]\n",
    "for one in ones:\n",
    "    # adjust conditions to one unit indicator\n",
    "    conditions = ((df_train['propertylandusetypeid'] == one) \n",
    "                  & (df_train['unitcnt'].isna()))\n",
    "    df_train.unitcnt.loc[conditions] = 1\n",
    "\n",
    "# two units \n",
    "twos = [31,47,246]\n",
    "for two in twos:\n",
    "    # adjust conditions to two unit indicator\n",
    "    conditions = ((df_train['propertylandusetypeid'] == two) \n",
    "                  & (df_train['unitcnt'].isna()))\n",
    "    df_train.unitcnt.loc[conditions] = 2\n",
    "\n",
    "# three units\n",
    "conditions = ((df_train['propertylandusetypeid'] == 247) \n",
    "              & (df_train['unitcnt'].isna()))\n",
    "df_train.unitcnt.loc[conditions] = 3\n",
    "\n",
    "# four units\n",
    "conditions = ((df_train['propertylandusetypeid'] == 248) \n",
    "              & (df_train['unitcnt'].isna()))\n",
    "df_train.unitcnt.loc[conditions] = 4\n",
    "\n",
    "# let's see how out unit counts look\n",
    "df_train.unitcnt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02yLicmxLs3C"
   },
   "source": [
    "### #8 Time to Cut\n",
    "**Because of the adjustments made so far a number of columns are no longer needed**\n",
    "*  transaction date column is no longer of use\n",
    "  - and can be dropped \n",
    "* `preimeter_living_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that `preimeter_living_area_sqft` has more duplicates\n",
    "* `total_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that \"total_area_sqft\" has more duplicates\n",
    "* `total_finished_living_area_sqft` and `finished_living_area_sqft` have the same values \n",
    "  - except that `finished_living_area_sqft` has more duplicates\n",
    "* `base_unfinished_and_finished_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
    "  - except that `base_unfinished_and_finished_area_sqft` has more duplicates\n",
    "* different counties follow different land use code\n",
    "  - to compare different counties, zillow has created it's own `propertylandusetypeid`\n",
    "    - hence we can drop `propertycountylandusecode`\n",
    "    - the same applies to `propertyzoningdesc`\n",
    "* Most zip id's either invalid or out of city\n",
    "  - since enough information about location is given in latitude and longitude \n",
    "    - let's drop other location related fields\n",
    "      - `regionidcity`\n",
    "      - `regionidzip`\n",
    "      - `regionidneighborhood`\n",
    "* `assessmentyear` has a constant value for all rows\n",
    "  - let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtOgzOqHLyid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: (2985342, 59)\n",
      "AFTER:  (2985342, 47)\n"
     ]
    }
   ],
   "source": [
    "print(f\"BEFORE: {df_train.shape}\")\n",
    "\n",
    "# collect columns to drop\n",
    "cut = ['propertyzoningdesc','propertycountylandusecode',\n",
    "       'base_unfinished_and_finished_area_sqft','finished_living_area_sqft',\n",
    "       'total_area_sqft','preimeter_living_area_sqft','regionidzip',\n",
    "       'regionidcity','regionidneighborhood','assessmentyear','transactiondate',\n",
    "       'censustractandblock']\n",
    "# cut columns form dataframe\n",
    "df_train = df_train.drop(cut, axis=1)\n",
    "\n",
    "print(f\"AFTER:  {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icDvpvSD6BSb"
   },
   "source": [
    "### #9 Tax, Year, & Census\n",
    "-  if tax deliquency flag is null, assume there is no unpaid tax on the property\n",
    "  - an issue arrises here because `taxdelinquencyflag` is a `StringColumn`\n",
    "    - i.e. null values indicate no tax delinquency, all other values are `Y` for yes\n",
    "    - because of this, the normal method of.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "8lYcO_T5XKNN",
    "outputId": "596cfad3-890d-4241-b8b8-347673082a7f"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDF failure at: /conda/conda-bld/libcudf_1584344789961/work/cpp/src/replace/replace.cu:885: Data type mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-739a1ab730d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# how we'd normally take care of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'taxdelinquencyflag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda-environments/rapids-nightly/lib/python3.7/site-packages/cudf/core/series.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The axis keyword is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda-environments/rapids-nightly/lib/python3.7/site-packages/cudf/core/column/string.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, fill_value)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibcudfxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_nulls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_first_and_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcudf/_libxx/replace.pyx\u001b[0m in \u001b[0;36mcudf._libxx.replace.replace_nulls\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcudf/_libxx/replace.pyx\u001b[0m in \u001b[0;36mcudf._libxx.replace.replace_nulls_scalar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDF failure at: /conda/conda-bld/libcudf_1584344789961/work/cpp/src/replace/replace.cu:885: Data type mismatch"
     ]
    }
   ],
   "source": [
    "# how we'd normally take care of this\n",
    "df_train['taxdelinquencyflag'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tA6xG6h59rLi"
   },
   "source": [
    "- ...comes with error. \n",
    "  - Why?\n",
    "    - the series we are trying to fill the null values of is a string series\n",
    "      - because of this `.fillna()` requires a sting value (e.g. '0') instead of an int value (e.g. 0)\n",
    "  - So, what now?\n",
    "    - there is an easy and straightforward solution with masked assigning!! \n",
    "      - First\n",
    "        - switch 1 (current True, actual False) to -1\n",
    "      - Then\n",
    "        - switch 0 (current False, actual True) to 1 to reflect True status\n",
    "      - Finally\n",
    "        - switch -1 (old True, actual False) to 0 to reflect False status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Svp6J0cJ5dL0",
    "outputId": "03862711-e104-4954-bf9c-61bd51b3a9e3"
   },
   "outputs": [],
   "source": [
    "# if bool 'Y'/None is already set, change string to int bool column via .isna()\n",
    "df_train['taxdelinquencyflag'] = df_train['taxdelinquencyflag'].isna()\n",
    "\n",
    "# next we must correct the values, with 1 (True) for 'Y' and 0 for no\n",
    "switcharoo = [(1,-1),(0,1),(-1,0)]\n",
    "# switch values in order\n",
    "for pair in switcharoo:\n",
    "  # tag old value and new value it will be replaced with\n",
    "  old, new = pair\n",
    "  # replace old value with new value\n",
    "  df_train['taxdelinquencyflag'] = df_train['taxdelinquencyflag'].replace(old, new)\n",
    "    \n",
    "# display values in tax delinquency flag column\n",
    "df_train['taxdelinquencyflag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5EAdWXaCTRU"
   },
   "source": [
    "- Convert years\n",
    "  - from yy\n",
    "    - to 2016 - yyyy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "6Bic66I9LfGC",
    "outputId": "baaa5387-bbd7-4242-a336-0b6b90606935"
   },
   "outputs": [],
   "source": [
    "# no delinquency? set year to 0\n",
    "df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyflag == 0] = 0\n",
    "\n",
    "# collect x and xx formatted delinquency years w/ matching xxxx year format pair\n",
    "year_pairs = [(99,1999), (6,2006), (7,2007), (8,2008), (9,2009), (10,2010),\n",
    "             (11,2011), (12,2012), (13,2013), (14,2014), (15,2015)]\n",
    "# go through the pairs individually \n",
    "for year in year_pairs:\n",
    "  # split the pair in question \n",
    "  old, new = year\n",
    "  # replace old year (e.g. 99) with new year (e.g. 1999)\n",
    "  df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear == old] = new\n",
    "\n",
    "# adjust delinquency year relative to training year (2016) \n",
    "df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear>0] = 2016 - df_train.taxdelinquencyyear.loc[df_train.taxdelinquencyyear>0]\n",
    "\n",
    "# what've we got? \n",
    "df_train.taxdelinquencyyear.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya7xLHzdGVcs"
   },
   "source": [
    "- values in `rawcensustractandblock` represent multiple fields concatened together as float values\n",
    "  - by converting those values to string we can split each and build new columns:\n",
    "    - `census_tractnumber`\n",
    "    - `block_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttt=df_train.copy()\n",
    "df_train=ttt.copy()\n",
    "\n",
    "# origional column\n",
    "\"\"\"\n",
    "\n",
    "# both are float columns now\n",
    "#rawcensustractandblock\n",
    "s_rawcensustractandblock=df_train.rawcensustractandblock.apply(lambda x: str(x))\n",
    "\n",
    "df_train['census_tractnumber']=s_rawcensustractandblock.str.slice(4,11)\n",
    "df_train['block_number']=s_rawcensustractandblock.str.slice(start=11)\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: x[:4]+'.'+x[4:]+'0' )\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: int(round(float(x),0)) )\n",
    "df_train['block_number']=df_train['block_number'].apply(lambda x: str(x).ljust(4,'0') )\n",
    "\n",
    "#droping censustractandblock since this is just a duplicate of rawcensustractandblock\n",
    "df_train=df_train.drop('censustractandblock', axis=1)\n",
    "\n",
    "# drooping rawcensustractandblock, since it's already stored as substrings in different column names\n",
    "df_train=df_train.drop('rawcensustractandblock', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "Sg0eN-K1QdZy",
    "outputId": "a90de47f-5c88-4834-df44-75a9dedcd07c"
   },
   "outputs": [],
   "source": [
    "# copy rawcensustractandblock with values as string instead of float\n",
    "string_data = cudf.Series(df_train['rawcensustractandblock'].values_to_string())\n",
    "\n",
    "# print(type(string_data))\n",
    "# print(len(string_data))\n",
    "# print(string_data)\n",
    "\n",
    "# \"\"\"\n",
    "# CURRENT ERROR IN CONVERSION OF VALUES\n",
    "# \"\"\"\n",
    "# print(f\"\\nNOTE: THERE APPEARS TO BE AN ERROR WHEN CONVERTING TO STRING\\n\"\n",
    "#       f\"  > somewhat random numbers added to end of some values\\n    >> e.g. 004, 006\"\n",
    "#       f\"\\n\\n\\ndf_train['rawcensustractandblock'].head(10).values\\n\"\n",
    "#       f\"{df_train['rawcensustractandblock'].head(10).values}\\n\\n\"\n",
    "#       f\"data.head(10).values\\n{string_data.head(10).values}\\n\\n\\n\"\n",
    "#       f\"THE SAME NUMBERS OCCOUR IN THE FIRST WHEN PUT INTO A LIST\\n\"\n",
    "#       f\"  > not sure how to deal with this now\\n\"\n",
    "#       f\"    >> difficult to reproduce without data\\n\\n\")\n",
    "# \"\"\"\n",
    "# CURRENT ERROR IN CONVERSION OF VALUES\n",
    "# \"\"\"\n",
    "\n",
    "# set new tract number \n",
    "df_train['census_tractnumber'] = string_data.str.slice(4, 11)\n",
    "\n",
    "# set/adjust block number\n",
    "df_train['block_number'] = string_data.str.slice(11)\n",
    "df_train['block_number'] = df_train.block_number.str.slice(0,4).str.cat(df_train.block_number.str.slice(4), '.')\n",
    "df_train['block_number'] = df_train.block_number.astype('float').round(0).astype('int')\n",
    "df_train['block_number'] = df_train.block_number.astype('str').str.ljust(4, '0')\n",
    "\n",
    "# drop raw census tract and block column, no longer needed\n",
    "df_train = df_train.drop('rawcensustractandblock', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "CORRECT NUMBERS THAT SHOULD BE DISPLAYED BY BELOW PRINT STATEMENT\n",
    "  > currently not being seen due to prior mentioned error\n",
    "\n",
    "tractnumber\n",
    "0    1066.46\n",
    "1    0524.22\n",
    "2    4638.00\n",
    "3    2963.00\n",
    "4    0423.38\n",
    "dtype: object\n",
    "\n",
    "blocknumber\n",
    "0    1001\n",
    "1    2024\n",
    "2    3004\n",
    "3    2002\n",
    "4    1006\n",
    "dtype: object\n",
    "\"\"\"\n",
    "df_train[['census_tractnumber', 'block_number']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T71orw51lpTN"
   },
   "source": [
    "## Dealing with Missing Values\n",
    "### #1 Setting standards\n",
    "- Despite corecting and adjusting the data to this point, there are still some columns holding a large majority of null values\n",
    "- For some columns, this majority represents over 95% of values\n",
    "  - Let's identify those columns\n",
    "    - And drop columns with more than 95% null values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "xhCosNpXvTVU",
    "outputId": "2d969756-decb-4912-94f6-19836eb0323a"
   },
   "outputs": [],
   "source": [
    "# calculate null value % for each column & frame it\n",
    "missingvalues_prop = (df_train.isnull().sum()/len(df_train)).reset_index()\n",
    "missingvalues_prop.columns = ['field','percentage']\n",
    "\n",
    "# sort by null values percentage, from highest % to lowest\n",
    "missingvalues_prop = missingvalues_prop.sort_values(by='percentage', \n",
    "                                                    ascending=False)\n",
    "# identify columns with > 95% of values null\n",
    "missingvaluescols = missingvalues_prop.loc[missingvalues_prop['percentage'] > 0.95]\n",
    "\n",
    "# display columns with highest % null values\n",
    "print(missingvaluescols)\n",
    "\n",
    "# drop columns with more than 95% null values\n",
    "df_train = df_train.drop(missingvaluescols['field'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "az6t2ntBCMRe"
   },
   "source": [
    "### #2 Working with Remaining Values\n",
    "- the majority of values still missing in unitcnt are rows were `propertylandusetypeid` = 265, \n",
    "  - which is Cluster Home (i.e. group of houses with shared walls)\n",
    "    - each cluster is anywhere between 5 to 25 units\n",
    "      - here we will asssume 10 units as reassonable count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "yB2lzAyopS_S",
    "outputId": "db6c7add-5452-4535-8948-a426654851b7"
   },
   "outputs": [],
   "source": [
    "# highly related propertylandusetypeid\n",
    "df_train['unitcnt'].loc[df_train['propertylandusetypeid'] == 265] = 10\n",
    "\n",
    "# let's see what we've got\n",
    "df_train['unitcnt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iR1rBlz-dOdH"
   },
   "source": [
    "- a number of pool sizes are null despite there being a pool\n",
    "  - let's calculate the average pool size\n",
    "    - and assume those null values are pools of average size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-icFDeLSoJwl",
    "outputId": "b1ed39c3-3a14-4dc1-eb48-b3429da5cffe"
   },
   "outputs": [],
   "source": [
    "# how's it look before?\n",
    "print(df_train.pool_sqft.isna().sum())\n",
    "\n",
    "# calculate the average pool square footage for properties with a pool(s)\n",
    "poolsizesum_mean = df_train.pool_sqft.loc[df_train['pool_count'] > 0].mean()\n",
    "\n",
    "# where the property has a pool(s) but pool square feet is 0\n",
    "conditions = ((df_train['pool_count'] > 0) \n",
    "              & (df_train['pool_sqft'].isna()==True))\n",
    "\n",
    "# set pool square feet to the average pool square footage of pool properties\n",
    "df_train['pool_sqft'].loc[conditions] = poolsizesum_mean\n",
    "\n",
    "# display new null count\n",
    "df_train.pool_sqft.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyGeXJfEmJBU"
   },
   "source": [
    "- total parcel tax\n",
    "- structure tax\n",
    "- land tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows have values in total parcel tax that do not add up given land tax and structure tax\n",
    "len(df_train.loc[df_train['total_parcel_tax'] != df_train['land_tax'] + df_train['structure_tax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.total_parcel_tax.isnull().sum())\n",
    "print(df_train.land_tax.isnull().sum())\n",
    "print()\n",
    "\n",
    "# where land tax is not a null value\n",
    "condition_1 = df_train.land_tax.isnull() == False\n",
    "# where total parceltax is not a null value\n",
    "condition_2 = df_train.total_parcel_tax.isnull()==False\n",
    "\n",
    "# pull the total parcel tax column\n",
    "total_parcel_tax_not_null = df_train.loc[condition_1 & condition_2, 'total_parcel_tax']\n",
    "# pull the land tax column\n",
    "land_tax_not_null = df_train.loc[condition_1 & condition_2, 'land_tax']\n",
    "\n",
    "# total_parcel_tax = structure_tax + land_tax\n",
    "# -> structure_tax = total_parcel_tax - land_tax\n",
    "correct_structure_tax = total_parcel_tax_not_null - land_tax_not_null\n",
    "\n",
    "# set the structure_tax values in rows where total and land taxes are not null to these correct values \n",
    "df_train['structure_tax'].loc[condition_1 & condition_2] = correct_structure_tax\n",
    "\n",
    "# where structure tax is still 0, there isn't structure tax\n",
    "df_train['structure_tax'].loc[df_train['structure_tax'] == 0] = np.nan\n",
    "\n",
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.total_parcel_tax.isnull().sum())\n",
    "print(df_train.land_tax.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows have values in total parcel tax that do not add up given land tax and structure tax\n",
    "len(df_train.loc[df_train['total_parcel_tax'] != df_train['land_tax'] + df_train['structure_tax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8SID48LOpYvu",
    "outputId": "6d20a3ba-4360-4554-908d-f6d673aece12"
   },
   "outputs": [],
   "source": [
    "# regionidcounty is exact copy of fips code, dropping the dulicate column\n",
    "df_train = df_train.drop(['regionidcounty'], axis=1)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tWmM2J8_pkg1",
    "outputId": "6362e07f-e363-4884-b0c5-9380b5fee956"
   },
   "outputs": [],
   "source": [
    "#*******************************\n",
    "#bedroomcnt #1421 zero bed room houses ??, observed it's missing all other room count also missing\n",
    "# where there is no bedroom, null is a better representation \n",
    "\n",
    "# before\n",
    "print(len(df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0]))\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "\n",
    "df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0] = np.nan\n",
    "\n",
    "# after\n",
    "print(len(df_train['bedroomcnt'].loc[df_train['bedroomcnt'] == 0]))\n",
    "print(df_train.bedroomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Room Count\n",
    "caluculate full bath and half bath again from total bath as it has few extra columns (fixes 500 missing values in roomcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "3qnP2L9LpmeJ",
    "outputId": "c0eabce4-3232-4435-8733-779526f18c57"
   },
   "outputs": [],
   "source": [
    "# propertylandusetypeid & total living area\n",
    "#                              total_bath           1165\n",
    "#                              full_bath           1182\n",
    "#                              half_bath           1182\n",
    "#                                bedroomcnt      1421\n",
    "#                              roomcnt           1416\n",
    "\n",
    "print(df_train.total_bath.isna().sum())\n",
    "print(df_train.full_bath.isnull().sum())\n",
    "print(df_train.half_bath.isnull().sum())\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.roomcnt.isnull().sum())\n",
    "print()\n",
    "\n",
    "# roomcnt = (full_bath + half_bath) + bedroomcnt\n",
    "# total_bath = fullbath+ 0.5(half_bath)\n",
    "\n",
    "# where full & half bath and bedroom count are not null, but room count is null\n",
    "conditions = ((df_train['full_bath'].isna() == False) \n",
    "              & (df_train['half_bath'].isna() == False) \n",
    "              & (df_train['bedroomcnt'].isna() == False) \n",
    "              & (df_train['roomcnt'].isna() == True))\n",
    "\n",
    "# calculate room count including all full & half baths along with bedroom count\n",
    "new_values = df_train.full_bath.loc[conditions] + df_train.half_bath.loc[conditions] + df_train.bedroomcnt.loc[conditions]\n",
    "\n",
    "# df_train['roomcnt'] = df_train['roomcnt'].masked_assign(new_values, conditions)\n",
    "df_train.roomcnt.loc[conditions] = new_values\n",
    "\n",
    "\n",
    "# most bedroom count and roomcount null are in same place\n",
    "# all column null count 1133 all columns are null\n",
    "\n",
    "print(df_train.total_bath.isna().sum())\n",
    "print(df_train.full_bath.isnull().sum())\n",
    "print(df_train.half_bath.isnull().sum())\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.roomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mvy51Ckev9CX"
   },
   "source": [
    "- correct number of stories by Zillow's `propertylandusetypeid` indicator\n",
    "  - where null values are not\n",
    "    - number of stories can be set to mode\n",
    "  - where there are null values\n",
    "    - number of stories can be set to the generally accepted number of stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IW4CG2InpolD",
    "outputId": "02375307-54e2-432b-8b87-1397c73d56b2"
   },
   "outputs": [],
   "source": [
    "# before (what's it look like?)\n",
    "print(f'BEFORE\\n{df_train.numberofstories.value_counts()}\\n'\n",
    "      f'{df_train.numberofstories.isnull().sum()} remaining null values\\n')\n",
    "\n",
    "#numberofstories\t69705\n",
    "\n",
    "# store ids and general number of stories \n",
    "zillow_type_ids = [(31,2), (246,2), (247,2), (248,2), (260,2), (261,1), \n",
    "                   (263,1), (266,1), (267,1), (269, 2), (275,1)]\n",
    "\n",
    "# go through each id pair \n",
    "for type_id in zillow_type_ids:\n",
    "    # split the pair into type id and number of stories\n",
    "    t_id, n_stories = type_id\n",
    "\n",
    "    # when type id matches and story count is not null\n",
    "    conditions = ((df_train['propertylandusetypeid'] == t_id) \n",
    "                  & (df_train['numberofstories'].isna() == False))\n",
    "\n",
    "    # calculate the mode story count for matching id properties\n",
    "    mode_stories = df_train.numberofstories.loc[conditions].value_counts()\n",
    "    \n",
    "    # when there is at least one value in the value_counts of this property type\n",
    "    if len(mode_stories) > 0:\n",
    "        # set mode stories to the most popular value\n",
    "        mode_stories = mode_stories[0]\n",
    "    # otherwise\n",
    "    else:\n",
    "        # set mode stories to the general average for this property type\n",
    "        mode_stories = n_stories\n",
    "\n",
    "    # and set those non null values to the most common value seen\n",
    "    df_train['numberofstories'].loc[conditions] = mode_stories\n",
    "\n",
    "    # when type id matches and story count is null\n",
    "    conditions = ((df_train['propertylandusetypeid'] == t_id) \n",
    "                  & (df_train['numberofstories'].isna() == False))\n",
    "    # set null values to the common number of stories seen in that type id\n",
    "    df_train['numberofstories'].loc[conditions] = n_stories\n",
    "\n",
    "# edge cases\n",
    "conditions = ((df_train.propertylandusetypeid==264) \n",
    "              & (df_train.numberofstories.isnull()))\n",
    "df_train.numberofstories.loc[conditions] = 2\n",
    "\n",
    "# what's it looking like? \n",
    "print(f'AFTER\\n{df_train.numberofstories.value_counts()}\\n'\n",
    "      f'{df_train.numberofstories.isnull().sum()} remaining null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "AHcMsDCxprd4",
    "outputId": "30481b2c-e035-4478-d62f-63e10a09c17e"
   },
   "outputs": [],
   "source": [
    "# before (what's it looking like?) \n",
    "print(f'BEFORE\\n{df_train.fireplace_count.value_counts()}\\n'\n",
    "      f'{df_train.fireplace_count.isnull().sum()} remaining null values\\n')\n",
    "\n",
    "# where there is a fire place, and count is not null\n",
    "conditions = ((df_train.fireplaceflag==1) \n",
    "              & (df_train.fireplace_count.isna() == False))\n",
    "# calculate the mode fireplace count \n",
    "mode_fire_count = df_train.loc[conditions, 'fireplace_count'].value_counts()[0]\n",
    "# and set those non null values to the most common fireplace count\n",
    "df_train['fireplace_count'].loc[conditions] = mode_fire_count\n",
    "\n",
    "# where there is a fire place, and count is null\n",
    "conditions = ((df_train.fireplaceflag==1) \n",
    "              & (df_train.fireplace_count.isna() == True))\n",
    "# set null values to the most common fireplace count\n",
    "df_train.fireplace_count.loc[conditions] = 1\n",
    "\n",
    "# after\n",
    "print(f'AFTER\\n{df_train.fireplace_count.value_counts()}\\n'\n",
    "      f'{df_train.fireplace_count.isnull().sum()} remaining null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "FIuSWoJspt3H",
    "outputId": "cb11c3a1-1658-4bce-cbde-a1a47ccdc0a8"
   },
   "outputs": [],
   "source": [
    "# set basic sns \n",
    "color = sns.color_palette()\n",
    "sns.set(style=\"darkgrid\")\n",
    "# convert dataframe to pandas for ease of use with sns\n",
    "pd_train = df_train.to_pandas()\n",
    "# set ax plot\n",
    "ax = sns.countplot(x=\"buildingqualitytypeid\", data=pd_train)\n",
    "# adjust fringe aesthetics\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Frequency of Bathroom count\", fontsize=15)\n",
    "# display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "KOHPCFRSp5y9",
    "outputId": "e0f3fe2e-a82a-49e8-a798-a3f79a30bcee"
   },
   "outputs": [],
   "source": [
    "# let's look more into year built vs type \n",
    "plt.plot(pd_train.yearbuilt, pd_train.buildingqualitytypeid, 'ro')\n",
    "# display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_647tI5Lp94v"
   },
   "source": [
    "### Final adjustments\n",
    "- filling nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofZIC0EdKJ0Y"
   },
   "source": [
    "# -----current: test ready-----\n",
    "- converting to pandas \n",
    "  - to see what's going on\n",
    "    - figuring out what can and what can't be replicated in cuML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4A3-sjRp8AE"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "# from cuml.preprocessing.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV,train_test_split\n",
    "#location seems to be related to building quality, (knnclassifier)\n",
    "\n",
    "def fillna_knn(df, base, target):\n",
    "    data_colnames = [target] + base\n",
    "    #print(\"data_colnames\",data_colnames)\n",
    "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
    "    #print(\"miss\",missing_values_boolflag.head())\n",
    "    not_missing_boolflag = ~missing_values_boolflag \n",
    "    #print(\"not miss\",not_missing_boolflag.head())\n",
    "    number_of_missing_val = missing_values_boolflag.sum()\n",
    "    print(\"# of miss\",number_of_missing_val)\n",
    "    not_missing_rows = df.loc[not_missing_boolflag, data_colnames]\n",
    "    #print(not_missing_rows.head())\n",
    "    Y = not_missing_rows[target]\n",
    "    X = not_missing_rows[base]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=3192,\n",
    "                                                        stratify=Y)\n",
    "    metrics       = ['euclidean'] \n",
    "    weights       = ['distance'] \n",
    "    numNeighbors  = [5,10,15,20,25]\n",
    "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
    "    cv            = StratifiedKFold(n_splits=3,random_state=3192,shuffle=False)\n",
    "    grid = GridSearchCV(neighbors.KNeighborsClassifier(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='f1_weighted',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "    grid.fit(X_train ,Y_train)\n",
    "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
    "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
    "    print(\"grid.best_params_\",grid.best_params_)\n",
    "    print(\"grid.scorer_\",grid.scorer_)\n",
    "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
    "    y_true, y_pred = Y_test, grid.predict(X_test)\n",
    "    \n",
    "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
    "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "AT8Osn51lD9v",
    "outputId": "8ab0690a-2e06-468e-b7ce-f4d051a3ce83"
   },
   "outputs": [],
   "source": [
    "print('CURRENT DF SITUATION\\n')\n",
    "\n",
    "print(f'SHAPE = {df_train.shape}')\n",
    "print(f'NULL COUNT = {df_train.buildingqualitytypeid.isnull().sum()}\\nVALUE COUNTS\\n{df_train.buildingqualitytypeid.value_counts()}\\n')\n",
    "\n",
    "df_train['buildingqualitytypeid'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "79bB7JKdAEtX",
    "outputId": "32b79160-fd19-4d39-988a-fc5fcd7c3284"
   },
   "outputs": [],
   "source": [
    "df_train['buildingqualitytypeid'] = df_train['buildingqualitytypeid'].fillna(-1)\n",
    "\n",
    "print(f'NULL COUNT = {df_train.buildingqualitytypeid.isnull().sum()}\\nVALUE COUNTS\\n{df_train.buildingqualitytypeid.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVgF1c_p_bN1"
   },
   "source": [
    "# -----current: break-----\n",
    "- break 1 of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "colab_type": "code",
    "id": "6eES-hq--NKZ",
    "outputId": "2bc86856-507d-47bf-cfab-d29649cba819"
   },
   "outputs": [],
   "source": [
    "# make safe copy\n",
    "test = df_train.copy()\n",
    "df_train = test.copy()\n",
    "# switch to pandas (figuring out what's going on)\n",
    "df_train = df_train.to_pandas()\n",
    "\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "colab_type": "code",
    "id": "mAB9bsrPAGzQ",
    "outputId": "d847758e-212e-4de8-85c4-89b469b71c48"
   },
   "outputs": [],
   "source": [
    "# say we run this whole thing by buildingqualitytypeid\n",
    "# drop building types that aren't seen at least 3 times in the data\n",
    "# df_train = df_train.groupby(\"buildingqualitytypeid\").filter(lambda x: x.buildingqualitytypeid.size > 3)\n",
    "\n",
    "# BACK TO cuDF\n",
    "df_train = cudf.from_pandas(df_train)\n",
    "\n",
    "print(df_train.buildingqualitytypeid.value_counts())\n",
    "print()\n",
    "print(df_train.buildingqualitytypeid.isnull().sum())\n",
    "print(df_train.shape)\n",
    "print()\n",
    "\n",
    "type_ids = list(set(df_train.buildingqualitytypeid.values))\n",
    "from time import sleep\n",
    "safe = []\n",
    "for tid in type_ids:\n",
    "  print(tid)\n",
    "  sleep(5)\n",
    "  t = len(df_train.loc[df_train.buildingqualitytypeid == tid])\n",
    "  if t > 3:\n",
    "    safe.append(tid)\n",
    "  else:\n",
    "    print(f'{tid} count too low @ {t}')\n",
    "for tid in type_ids:\n",
    "  if tid not in safe:\n",
    "    df_train = df_train.loc[df_train.buildingqualitytypeid != tid]\n",
    "\n",
    "print()\n",
    "print(df_train.buildingqualitytypeid.value_counts())\n",
    "print()\n",
    "\n",
    "df_train['buildingqualitytypeid'] = df_train['buildingqualitytypeid'].replace(-1,np.nan)\n",
    "print(df_train.buildingqualitytypeid.isnull().sum())\n",
    "print(df_train.shape)\n",
    "\n",
    "# BACK TO PANDAS\n",
    "df_train = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zl7eXGt_g1uU"
   },
   "source": [
    "# -----current: break-----\n",
    "- break 2 of 2\n",
    "  - below is last cell run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "Q3ZBSOHm-79A",
    "outputId": "e9ddb9b3-0bb0-4cf7-fa8e-ca35b9ea7f46"
   },
   "outputs": [],
   "source": [
    "# run cell above (currently broken) as would be in pandas\n",
    "not_df_train = df_train.to_pandas()\n",
    "not_df_train = not_df_train.groupby(\"buildingqualitytypeid\").filter(lambda x: x.buildingqualitytypeid.size > 3)\n",
    "\n",
    "missing_values = fillna_knn(not_df_train, \n",
    "                            base = ['latitude', 'longitude'], \n",
    "                            target = 'buildingqualitytypeid')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = not_df_train['buildingqualitytypeid'].isnull()\n",
    "not_df_train.loc[missing_values_boolflag, 'buildingqualitytypeid'] = missing_values\n",
    "\n",
    "print(not_df_train.buildingqualitytypeid.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgXh5OATEacY"
   },
   "source": [
    "# BELOW NOT (really) RUN\n",
    "- if run, was in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "oTh_XPErqkHf",
    "outputId": "3e667bca-70c5-4b66-c7d2-12d171cb140b"
   },
   "outputs": [],
   "source": [
    "print(df_train.heating_system_id.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['heating_system_id']=temp['heating_system_id'].fillna(-1)\n",
    "temp=temp.groupby(\"heating_system_id\").filter(lambda x: x.heating_system_id.size > 3)\n",
    "temp['heating_system_id'] = temp['heating_system_id'].replace(-1,np.nan)\n",
    "print(temp.heating_system_id.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'heating_system_id')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['heating_system_id'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'heating_system_id' ]  = missing_values\n",
    "\n",
    "\n",
    "print(df_train.heating_system_id.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "oVjNSkUYqnCt",
    "outputId": "80fc7e87-36cd-44b7-96e9-ef0631c7d10c"
   },
   "outputs": [],
   "source": [
    "print(df_train.ac_id.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['ac_id']=temp['ac_id'].fillna(-1)\n",
    "temp=temp.groupby(\"ac_id\").filter(lambda x: x.ac_id.size > 3)\n",
    "temp['ac_id'] = temp['ac_id'].replace(-1,np.nan)\n",
    "print(temp.ac_id.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'ac_id')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['ac_id'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'ac_id' ]  = missing_values\n",
    "\n",
    "print(df_train.ac_id.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "qTbcYbexqr0Y",
    "outputId": "3459affa-a41a-4241-ab62-f0dfcadda039"
   },
   "outputs": [],
   "source": [
    "#yearbuilt\n",
    "print(df_train.yearbuilt.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "temp['yearbuilt']=temp['yearbuilt'].fillna(-1)\n",
    "temp=temp.groupby(\"yearbuilt\").filter(lambda x: x.yearbuilt.size > 3)\n",
    "temp['yearbuilt'] = temp['yearbuilt'].replace(-1,np.nan)\n",
    "print(temp.yearbuilt.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knn(temp,\n",
    "                  base = [ 'latitude', 'longitude','buildingqualitytypeid','propertylandusetypeid' ] ,\n",
    "                  target = 'yearbuilt')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['yearbuilt'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'yearbuilt' ]  = missing_values\n",
    "print(df_train.yearbuilt.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx1LYGmfqxLk"
   },
   "outputs": [],
   "source": [
    "#location seems to be related to building quality, (knnregressor)\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def fillna_knnr( df, base, target):\n",
    "    data_colnames = [ target ] + base\n",
    "    #print(\"data_colnames\",data_colnames)\n",
    "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
    "    #print(\"miss\",missing_values_boolflag.head())\n",
    "    not_missing_boolflag = ~missing_values_boolflag \n",
    "    #print(\"not miss\",not_missing_boolflag.head())\n",
    "    number_of_missing_val = missing_values_boolflag.sum()\n",
    "    print(\"# of miss\",number_of_missing_val)\n",
    "    not_missing_rows = df.loc[ not_missing_boolflag, data_colnames]\n",
    "    #print(not_missing_rows.head())\n",
    "    Y = not_missing_rows[target]\n",
    "    X = not_missing_rows[base]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=3192)\n",
    "    metrics       = ['euclidean'] \n",
    "    weights       = ['distance'] \n",
    "    numNeighbors  = [5,10,15,20,25]\n",
    "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
    "    cv            = KFold(n_splits=3,random_state=3192,shuffle=False) \n",
    "    grid = GridSearchCV(neighbors.KNeighborsRegressor(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='neg_mean_absolute_error',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "    grid.fit(X_train ,Y_train)\n",
    "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
    "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
    "    print(\"grid.best_params_\",grid.best_params_)\n",
    "    print(\"grid.scorer_\",grid.scorer_)\n",
    "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
    "    y_true, y_pred = Y_test, grid.predict(X_test) \n",
    "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
    "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "pj5PXm7ozg5l",
    "outputId": "3d42279f-221c-444c-8795-05a0832f97cd"
   },
   "outputs": [],
   "source": [
    "#garage_sqft\n",
    "print(df_train.garage_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.loc[df_train.garagecarcnt>0,df_train.columns].copy()\n",
    "\n",
    "print(temp.garage_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = [ 'latitude', 'longitude','garagecarcnt'] ,\n",
    "                  target = 'garage_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['garage_sqft'].isnull()\n",
    "df_train.loc[missing_values_boolflag, 'garage_sqft'] = missing_values\n",
    "print(df_train.garage_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7e5CFTyzg_M"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop('parcelid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxGquCOOzhD7"
   },
   "outputs": [],
   "source": [
    "#All the other columns with missing values seems to be  integer, will need regression to be imputed,\n",
    "#time to get categorical variables hot encoded\n",
    "\n",
    "#Identify numerical columns to produce a heatmap\n",
    "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips', 'heating_system_id','has_hottub_or_spa',\n",
    "          'just_hottub_or_spa', 'pool_with_spa_tub_yes','pool_with_spa_tub_no','propertylandusetypeid','basement_flag'\n",
    "          ,'fireplaceflag','taxdelinquencyflag']\n",
    "numcols = [x for x in df_train.columns if x not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVZkszJEzhHj"
   },
   "outputs": [],
   "source": [
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_finished_living_area_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_finished_living_area_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = [ 'latitude', 'longitude','basementsqft','numberofstories','poolcnt','garagecarcnt','garage_sqft','propertylandusetypeid'] ,\n",
    "                  target = 'total_finished_living_area_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_finished_living_area_sqft'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_finished_living_area_sqft' ] = missing_values\n",
    "print(df_train.total_finished_living_area_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVrTMb92zhLX"
   },
   "outputs": [],
   "source": [
    "#total_bath\t1165\n",
    "#full_bath\t1182\n",
    "#half_bath\t1182\n",
    "#roomcnt\t1416\n",
    "#bedroomcnt\t1421\n",
    "\n",
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_bath.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_bath.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
    "                  target = 'total_bath')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_bath'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
    "print(df_train.total_bath.isnull().sum())#total_bath\t1165\n",
    "#full_bath\t1182\n",
    "#half_bath\t1182\n",
    "#roomcnt\t1416\n",
    "#bedroomcnt\t1421\n",
    "\n",
    "#total_finished_living_area_sqft\n",
    "\n",
    "print(df_train.total_bath.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_bath.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
    "                  target = 'total_bath')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_bath'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
    "print(df_train.total_bath.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjIKlu-tzhPI"
   },
   "outputs": [],
   "source": [
    "# rop half_bath and full bath, as there are only redundant values of total_bath\n",
    "df_train = df_train.drop(['full_bath','half_bath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02X1y6EBzhT9"
   },
   "outputs": [],
   "source": [
    "#bedroomcnt\t1421\n",
    "\n",
    "print(df_train.bedroomcnt.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.bedroomcnt.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['propertylandusetypeid','total_finished_living_area_sqft','total_bath' ] ,\n",
    "                  target = 'bedroomcnt')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['bedroomcnt'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'bedroomcnt' ] = missing_values\n",
    "print(df_train.bedroomcnt.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzkZ_qeHzhXP"
   },
   "outputs": [],
   "source": [
    "df_train['total_bath']=df_train.total_bath.round(1)\n",
    "df_train['bedroomcnt']=df_train.bedroomcnt.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF9DtDAczhaW"
   },
   "outputs": [],
   "source": [
    "#recalculate roomcnt\t1416 as we have used imputation for total_bath and bedroomcnt\n",
    "\n",
    "df_train.loc[(df_train.roomcnt.isnull()),['roomcnt']]=df_train.total_bath + df_train.bedroomcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5N41TBlz60W"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "df_train =df_train.loc[(df_train.total_parcel_tax.notnull()) & (df_train.land_tax.notnull()),df_train.columns]\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv9h5yL3z64Q"
   },
   "outputs": [],
   "source": [
    "#lot_area_sqft\n",
    "print(df_train.lot_area_sqft.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.lot_area_sqft.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'lot_area_sqft')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['lot_area_sqft'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'lot_area_sqft' ] = missing_values.round(2)\n",
    "print(df_train.lot_area_sqft.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYJLHrR4z68f"
   },
   "outputs": [],
   "source": [
    "# predict structure_tax and recalculate  total_parcel_tax = land_tax + structure_tax\n",
    "\n",
    "\n",
    "print(df_train.structure_tax.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.structure_tax.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'structure_tax')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['structure_tax'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'structure_tax' ] = missing_values.round(2)\n",
    "print(df_train.structure_tax.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya-3K06Zz6_y"
   },
   "outputs": [],
   "source": [
    "#36 total_property_tax_2016 \n",
    "\n",
    "#total_parcel_tax = land_tax + structure_tax\n",
    "    \n",
    "df_train['total_parcel_tax']=df_train['structure_tax']+df_train['land_tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fvr7voVz7DX"
   },
   "outputs": [],
   "source": [
    "#age of the property\n",
    "df_train['age'] = 2016 - df_train['yearbuilt']\n",
    "df_train=df_train.drop(['yearbuilt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xl0EOIT-z7Gl"
   },
   "outputs": [],
   "source": [
    "#total_property_tax_2016\n",
    "\n",
    "\n",
    "print(df_train.total_property_tax_2016.isnull().sum())\n",
    "print(df_train.shape)\n",
    "temp=df_train.copy()\n",
    "print(temp.total_property_tax_2016.isnull().sum())\n",
    "print(temp.shape)\n",
    "missing_values=fillna_knnr(temp,\n",
    "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
    "                  target = 'total_property_tax_2016')\n",
    "\n",
    "print(\"predicted output shape\",missing_values.shape)\n",
    "missing_values_boolflag = df_train['total_property_tax_2016'].isnull()\n",
    "df_train.loc[ missing_values_boolflag, 'total_property_tax_2016' ] = missing_values.round(2)\n",
    "print(df_train.total_property_tax_2016.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlaxWegqz7I-"
   },
   "outputs": [],
   "source": [
    "#check missing values\n",
    "\n",
    "missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.loc[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "print(missing_df)\n",
    "print(missing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIl_nqKVz7NQ"
   },
   "outputs": [],
   "source": [
    "#both the columns above miss 92% of the data, there is no related varibale to impute it, hence dropping them at this point\n",
    "\n",
    "df_train = df_train.drop(['finished_living_area_entryfloor_sqft2','finished_living_area_entryfloor_sqft1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQJd7rgKz7Qq"
   },
   "outputs": [],
   "source": [
    "#Identify numerical columns to produce a heatmap\n",
    "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips','pool_with_spa_tub_no','pool_with_spa_tub_yes','has_hottub_or_spa',\n",
    "           'just_hottub_or_spa','heating_system_id','propertylandusetypeid','basement_flag','fireplaceflag','taxdelinquencyflag']\n",
    "numcols = [x for x in df_train.columns if x not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUN3a6uJz7Ut"
   },
   "outputs": [],
   "source": [
    "# 2 variables are in object datatype, coverting into numeric\n",
    "df_train[['census_tractnumber','block_number']] = df_train[['census_tractnumber','block_number']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGx77rRAz7ZZ"
   },
   "outputs": [],
   "source": [
    "# dropping categorical columns as xgboost feature selection cannot hadle it\n",
    "\n",
    "train_x = df_train.drop(catcols+['logerror'], axis=1)\n",
    "\n",
    "train_y=df_train['logerror']\n",
    "\n",
    "train_x = train_x.astype(float) \n",
    "train_y = train_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "es_Ew2YJz7dT"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 65\n",
    "\n",
    "dtype_df = train_x.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
    "#dtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvWIhR38z7fW"
   },
   "outputs": [],
   "source": [
    "df_train.loc[df_train.has_hottub_or_spa==True,'has_hottub_or_spa']=\"Yes\"\n",
    "df_train.loc[df_train.has_hottub_or_spa==0,'has_hottub_or_spa']=\"No\"\n",
    "\n",
    "df_train.loc[df_train.just_hottub_or_spa==0,'just_hottub_or_spa']=\"No\"\n",
    "df_train.loc[df_train.just_hottub_or_spa==1,'just_hottub_or_spa']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.deck_flag==0,'deck_flag']=\"No\"\n",
    "df_train.loc[df_train.deck_flag==1,'deck_flag']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.basement_flag==0,'basement_flag']=\"No\"\n",
    "df_train.loc[df_train.basement_flag==1,'basement_flag']=\"Yes\"\n",
    "\n",
    "df_train.loc[df_train.fireplaceflag==False,'fireplaceflag']=\"No\"\n",
    "df_train.loc[df_train.fireplaceflag==True,'fireplaceflag']=\"Yes\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ef9JjrmMz7jw"
   },
   "outputs": [],
   "source": [
    "#ac_id,heating_system_id,propertylandusetypeid\n",
    "dummieslist=['has_hottub_or_spa','just_hottub_or_spa',\n",
    "             'deck_flag','fips','basement_flag','fireplaceflag','taxdelinquencyflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z51Zrt2Uz7oD"
   },
   "outputs": [],
   "source": [
    "df_train[dummieslist] = df_train[dummieslist].astype(object)\n",
    "dummies = pd.get_dummies(df_train[dummieslist], prefix= dummieslist)\n",
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHBi5Gg6z7tu"
   },
   "outputs": [],
   "source": [
    "dummies2=['pool_with_spa_tub_no','pool_with_spa_tub_yes']\n",
    "df_train[dummies2] = df_train[dummies2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oocTPKI9z7rk"
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "from sqlalchemy import create_engine\n",
    "engineString = 'mysql+mysqldb://root:MyNewPass@localhost/sakila'\n",
    "engine = create_engine(engineString)\n",
    "con=engine.connect()\n",
    "\n",
    "with engine.connect() as con, con.begin():\n",
    "    df_train.to_sql('df_train_f1', engine, chunksize=10000, index =False,if_exists ='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zj5ZLSPlz7XC"
   },
   "outputs": [],
   "source": [
    "numcols2=['basementsqft','total_bath','bedroomcnt','total_finished_living_area_sqft','fireplace_count','garagecarcnt',\n",
    " 'garage_sqft','latitude','longitude','lot_area_sqft','poolcnt','pool_sqft','roomcnt','unitcnt','patio_sqft','storage_sqft',\n",
    " 'numberofstories','structure_tax','total_parcel_tax','land_tax','total_property_tax_2016','taxdelinquencyyear','transaction_month',\n",
    " 'census_tractnumber','block_number','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fp53dotszhgA"
   },
   "outputs": [],
   "source": [
    "Y=df_train['logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0Uaei4rzhj6"
   },
   "outputs": [],
   "source": [
    "#buildingqualitytypeid ->has order\n",
    "le = LabelEncoder()\n",
    "df_train['buildingqualitytypeid']=le.fit_transform(df_train.buildingqualitytypeid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4-g-uvtzhds"
   },
   "outputs": [],
   "source": [
    "#df_train.ac_id.value_counts()\n",
    "#df_train.propertylandusetypeid.value_counts()\n",
    "#'buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzliXafdzhRd"
   },
   "outputs": [],
   "source": [
    "X=pd.concat([dummies,df_train[dummies2],df_train[numcols2],df_train[['buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid']]],axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBsZjyQd0W1N"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=3192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihXFZWcn0W5D"
   },
   "outputs": [],
   "source": [
    "#  top features\n",
    "import xgboost as xgb\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    'seed' : 0\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train, Y_train, feature_names=X_train.columns.values)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "#max_num_features=50, error for no reason \n",
    "xgb.plot_importance(model, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQEEzNkX0W9w"
   },
   "outputs": [],
   "source": [
    "#top features\n",
    "xgboost_selection=['total_finished_living_area_sqft','latitude','structure_tax','total_property_tax_2016',\n",
    "'total_parcel_tax','land_tax','longitude','lot_area_sqft','census_tractnumber','age','total_bath','bedroomcnt',\n",
    "'block_number','transaction_month','roomcnt','taxdelinquencyyear','unitcnt','taxdelinquencyflag_No',\n",
    "'fips_LA','garage_sqft','pool_with_spa_tub_no','has_hottub_or_spa_No','garagecarcnt','deck_flag_No',\n",
    "'poolcnt','pool_sqft'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rr_6EO4G0XEj"
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "#c_id,heating_system_id,propertylandusetypeid\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "reg = ExtraTreesRegressor(n_estimators=500, max_depth=8, max_features='sqrt',\n",
    "                          min_samples_split=100 ,min_samples_leaf=10, bootstrap=True,n_jobs=-1, random_state=3192)\n",
    "reg = reg.fit(X_train, Y_train)\n",
    "#print(\"importance\",reg.feature_importances_) \n",
    "model = SelectFromModel(reg, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_new.shape)  \n",
    "\n",
    "feat_names = X.columns.values\n",
    "importances = reg.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in reg.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1][:26]\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4FCNOG70XIU"
   },
   "outputs": [],
   "source": [
    "tree_selection=[\n",
    "    'total_finished_living_area_sqft','structure_tax','total_property_tax_2016','total_bath','total_parcel_tax',\n",
    "    'age','latitude','census_tractnumber','bedroomcnt','longitude','land_tax','propertylandusetypeid','block_number',\n",
    "    'buildingqualitytypeid','numberofstories','heating_system_id','unitcnt','transaction_month','lot_area_sqft','roomcnt',\n",
    "    'garage_sqft','garagecarcnt','pool_with_spa_tub_no','poolcnt','fips_LA','taxdelinquencyyear','patio_sqft',\n",
    "    'taxdelinquencyflag_No','taxdelinquencyflag_Yes'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmIS1WAS0XMW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer\n",
    "\n",
    "#model=Lasso(alpha=0.2, fit_intercept=True, normalize=True, precompute=False, copy_X=True,\n",
    " #                                max_iter=1000, \n",
    "  #                               tol=0.0001, warm_start=False, positive=False, random_state=3192, selection='cyclic')\n",
    "\n",
    "#Ridge(random_state=3192,solver='auto',fit_intercept=True,normalize=True,alpha=0.1)\n",
    "#LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True)\n",
    "\n",
    "\n",
    "rfecv = RFECV(estimator=LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True), step=2, cv=KFold(4),scoring='neg_mean_absolute_error')\n",
    "rfecv.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIw8O00U0XPR"
   },
   "outputs": [],
   "source": [
    "rfe_selection = [i for indx,i in enumerate(X.columns) if rfecv.support_[indx] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHA0x5_80XWy"
   },
   "outputs": [],
   "source": [
    "#Linear regression with rfe_selection selection\n",
    "#rfe_selection, tree_selection, xgboost_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer,mean_squared_error\n",
    "\n",
    "# just to check whether normalized /not normalized data gives better results\n",
    "parameters = {'fit_intercept':[True], 'normalize':[True,False], 'copy_X':[True]}\n",
    "scoring = {'MAE':'neg_mean_absolute_error','MSE': make_scorer(mean_squared_error,greater_is_better=False)}\n",
    "\n",
    "grid1 = GridSearchCV(LinearRegression(n_jobs=-1),param_grid=parameters, scoring=scoring,cv=5,refit='MAE',\n",
    "                    return_train_score=True,\n",
    "                    verbose=0,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "\n",
    "grid1.fit(X_train[rfe_selection], Y_train)\n",
    "#print(\"5. grid best_score_\",abs(grid.best_score_))\n",
    "Y_pred = grid1.predict(X_test[rfe_selection])\n",
    "print(\"MAE on test data\",mean_absolute_error(Y_test,Y_pred))\n",
    "print(\"MSE on test data\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R Squared data \",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekn4pBs60XcT"
   },
   "outputs": [],
   "source": [
    "#pca selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "scaled_x = scale(X)\n",
    "pca = PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFuT-wUN0XfV"
   },
   "outputs": [],
   "source": [
    "# The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPN4OBUe0XlD"
   },
   "outputs": [],
   "source": [
    "#Looking at above plot I'm taking 28 variables\n",
    "\n",
    "pca = PCA(n_components=28, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)\n",
    "\n",
    "pca1=pca.fit_transform(scaled_x)\n",
    "\n",
    "pca = PCA(n_components=28, copy=True, whiten=True, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
    "pca.fit(scaled_x)\n",
    "pca2=pca.fit_transform(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EE4ednPC0XjX"
   },
   "outputs": [],
   "source": [
    "pcaX_train, pcaX_test, pcaY_train, pcaY_test = train_test_split(pca1, Y, test_size=0.10, random_state=3192)\n",
    "pca2X_train, pca2X_test, pca2Y_train, pca2Y_test = train_test_split(pca2, Y, test_size=0.10, random_state=3192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erYMXvTG0XaK"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# just to check whether normalized /not normalized data gives better results\n",
    "\n",
    " # 0.005 for 1200 trees.\n",
    "param_grid={'n_estimators':[1200],'max_features':[22]}\n",
    "\n",
    "              \n",
    "grid13 = GridSearchCV(GradientBoostingRegressor(subsample=0.8,min_samples_leaf=50,min_samples_split=50,max_depth=9,loss='ls',criterion='friedman_mse',learning_rate=0.005,random_state=3192),\n",
    "                     param_grid=param_grid, cv=5,refit='MAE',\n",
    "                    return_train_score=True,\n",
    "                    verbose=2,n_jobs=-1,pre_dispatch='n_jobs')\n",
    "\n",
    "grid13.fit(pcaX_train, pcaY_train)\n",
    "print(\"5. grid best_score_\",abs(grid13.best_score_))\n",
    "print(\"best params\",grid13.best_params_)\n",
    "print(\"best score\",grid13.best_score_)\n",
    "Y_pred = grid13.predict(pcaX_test)\n",
    "print(\"MAE on test data\",mean_absolute_error(pcaY_test,Y_pred))\n",
    "print(\"MSE on test data\",mean_squared_error(pcaY_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgtbLCcR0XUx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjdSCEFP0XCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzATgLxmam5w"
   },
   "source": [
    "In this competition, Zillow is asking you to predict the log-error between their Zestimate and the actual sale price, given all the features of a home. The log error is defined as\n",
    "\n",
    "logerror=log(Zestimate)−log(SalePrice)\n",
    "and it is recorded in the transactions file train.csv. In this competition, you are going to predict the logerror for the months in Fall 2017. Since all the real estate transactions in the U.S. are publicly available, we will close the competition (no longer accepting submissions) before the evaluation period begins.\n",
    "\n",
    "Train/Test split\n",
    "You are provided with a full list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) data in 2016.\n",
    "The train data has all the transactions before October 15, 2016, plus some of the transactions after October 15, 2016.\n",
    "The test data in the public leaderboard has the rest of the transactions between October 15 and December 31, 2016.\n",
    "The rest of the test data, which is used for calculating the private leaderboard, is all the properties in October 15, 2017, to December 15, 2017. This period is called the \"sales tracking period\", during which we will not be taking any submissions.\n",
    "You are asked to predict 6 time points for all properties: October 2016 (201610), November 2016 (201611), December 2016 (201612), October 2017 (201710), November 2017 (201711), and December 2017 (201712).\n",
    "Not all the properties are sold in each time period. If a property was not sold in a certain time period, that particular row will be ignored when calculating your score.\n",
    "If a property is sold multiple times within 31 days, we take the first reasonable value as the ground truth. By \"reasonable\", we mean if the data seems wrong, we will take the transaction that has a value that makes more sense.\n",
    "File descriptions\n",
    "properties_2016.csv - all the properties with their home features for 2016. Note: Some 2017 new properties don't have any data yet except for their parcelid's. Those data points should be populated when properties_2017.csv is available.\n",
    "properties_2017.csv - all the properties with their home features for 2017 (released on 10/2/2017)\n",
    "train_2016.csv - the training set with transactions from 1/1/2016 to 12/31/2016\n",
    "train_2017.csv - the training set with transactions from 1/1/2017 to 9/15/2017 (released on 10/2/2017)\n",
    "sample_submission.csv - a sample submission file in the correct format"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "zillow_kaggle_zestimate_comp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "RAPIDS Nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
